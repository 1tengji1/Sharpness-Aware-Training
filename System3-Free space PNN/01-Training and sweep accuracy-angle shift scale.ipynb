{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:16.989558Z",
     "start_time": "2025-05-30T04:48:13.704238Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\GPU_Pytorchpy39\\lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "import angular_spectrum_tensor_v1 as AST\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "import mydata\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5c8a79f6b2a84f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:22.074787Z",
     "start_time": "2025-05-30T04:48:20.760652Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Hyper parameters \"\"\"\n",
    "\n",
    "# training parameters\n",
    "Device=torch.device('cuda' if torch.cuda.is_available() else'cpu')\n",
    "batch_size = 64\n",
    "learning_rate=3e-3\n",
    "epochs=30\n",
    "\n",
    "# physical parameters\n",
    "\n",
    "lambda_0=532e-3\n",
    "\n",
    "\n",
    "def Microscope_equiv(res,F,Lmeasure,lambda_0=0.532):\n",
    "    \"\"\"transform a microscope system into a single lens\"\"\"\n",
    "    din=Lmeasure/(1+F)# euqvalient din by measurement\n",
    "    dout=din*F\n",
    "    D_equal=(1.22*lambda_0/res)*din #the equavalient D\n",
    "    f_equal=1/(1/din+1/dout)\n",
    "    return D_equal,f_equal\n",
    "\n",
    "res=5 #system resolution\n",
    "lamda_0=0.532\n",
    "FF=1\n",
    "Lmeasure=500e3\n",
    "\n",
    "[D1,f1]=Microscope_equiv(res,FF,Lmeasure)\n",
    "res=8 #system resolution\n",
    "lamda_0=0.532\n",
    "#F=1\n",
    "FF=1\n",
    "\n",
    "Lmeasure=400e3\n",
    "[D2,f2]=Microscope_equiv(res,FF,Lmeasure)\n",
    "\n",
    "\n",
    "\n",
    "mask1=AST.create_unit_mask_2D(3*32,4*2*30)\n",
    "mask2=AST.create_unit_mask_2D(3*32,4*2*30)\n",
    "\n",
    "Bool_mask1=AST.create_Binary_mask_2D(3*32,4*2*30)\n",
    "Bool_mask2=AST.create_Binary_mask_2D(3*32,4*2*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcd2e46f1b1c2423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:23.101990Z",
     "start_time": "2025-05-30T04:48:23.089245Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name='xoyr+dark_new'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b727aa27ed6c9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### change the injection level by tuning the magnitude of NL_ys(2) or NL_xs(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "583d816cf3f57b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:23.818100Z",
     "start_time": "2025-05-30T04:48:23.808747Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as F_vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87c9e6585b896e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:25.437714Z",
     "start_time": "2025-05-30T04:48:25.429740Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" forward,layer 1 \"\"\"\n",
    "angle = 0\n",
    "shift_y = 0\n",
    "scale = 1\n",
    "def f_wn_1(x,theta):\n",
    "        \"\"\"  weight transformation \"\"\"\n",
    "        w1_temp = AST.MiddlePicture_single_tensor(theta,mask1)\n",
    "        w1_temp = (F_vision.affine(w1_temp, angle=angle, translate=(0,shift_y), scale=scale, shear=0.0))        \n",
    "        w1_temp=AST.MiddlePicture2Vector(w1_temp).to(Device)\n",
    "        x = torch.matmul(x,w1_temp).to(Device)\n",
    "        return x\n",
    "\"\"\" forward,layer 2\"\"\"\n",
    "def f_wn_2(x,theta):\n",
    "        \"\"\"  weight transformation \"\"\"\n",
    "        w2_temp=AST.BigPicture_single_tensor_2D(theta,mask2,RawNumber=3,ColumnNumber=4,paddcol=30,paddraw=32,dim_in=12,num_out=10)\n",
    "        w2_temp = (F_vision.affine(w2_temp.unsqueeze(0), angle=0, translate=(0,0), scale=scale, shear=0.0))        \n",
    "        w2_temp=AST.BigPicture2Vector_2D(w2_temp,RawNumber=3,ColumnNumber=4,paddcol=30,paddraw=32,dim_in=12,num_out=10).to(Device)\n",
    "        w2_temp = w2_temp.squeeze(0)\n",
    "        x=torch.matmul(x,w2_temp).to(Device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80602f290a93d49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:26.182991Z",
     "start_time": "2025-05-30T04:48:26.162993Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Define NN class\"\"\"\n",
    "class InCoFCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InCoFCNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 144)\n",
    "        self.fc2 = nn.Linear(144, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = f_wn_1(x,self.fc1.weight.t())+self.fc1.bias\n",
    "        x = F.sigmoid(x)\n",
    "        x = f_wn_2(x,self.fc2.weight.t())+self.fc2.bias\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def apply_constraints(self):\n",
    "        self.fc1.weight.data = torch.clamp(self.fc1.weight.data,-1,1)        \n",
    "        self.fc2.weight.data = torch.clamp(self.fc2.weight.data,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "484ca3d3cc6cb9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:27.175316Z",
     "start_time": "2025-05-30T04:48:27.121987Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" data loading \"\"\"\n",
    "transform0 = transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081,))])\n",
    "\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform0)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b62c5f65af6f566",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:28.643748Z",
     "start_time": "2025-05-30T04:48:28.638824Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = InCoFCNet().to(Device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(net.parameters(),lr=learning_rate*0.5,betas=(0.9,0.999))\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99802fceace47fbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:58:21.683767Z",
     "start_time": "2025-05-30T04:48:31.729215Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Standard BP\"\"\"\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "        inputs = inputs.view(inputs.size(0), -1).to(Device)  # 将输入数据展平\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        net.apply_constraints()      \n",
    "        running_loss += loss.item()\n",
    "        if i % 600 == 599:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 600:.3f} Classification loss:{loss.cpu().detach().numpy():.3f}')\n",
    "            running_loss = 0.0\n",
    "    scheduler.step()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "            inputs = inputs.view(inputs.size(0), -1) \n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(inputs)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy 10000 test images: {100 * correct / total} %')\n",
    "print('Finished Training')\n",
    "y_pred = []\n",
    "t_pred = []\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "    inputs = inputs.view(-1, 784)\n",
    "    # calculate outputs by running images through the network\n",
    "    outputs = net(inputs)\n",
    "    # the class with the highest energy is what we choose as prediction\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    y = predicted.view(-1).cpu().detach().numpy()\n",
    "    t = labels.view(-1).cpu().detach().numpy()\n",
    "    for i in range(len(predicted)):\n",
    "        y_pred.append(y[i])\n",
    "        t_pred.append(t[i])\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print(f'W noise Accuracy 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9327bbe90b153681",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:00:22.469216Z",
     "start_time": "2025-05-30T05:00:22.461965Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net_ref=net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "113cbae551f37dbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:00:23.280705Z",
     "start_time": "2025-05-30T05:00:23.264226Z"
    }
   },
   "outputs": [],
   "source": [
    "from sam import SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "548e45a789dddf90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:00:23.733164Z",
     "start_time": "2025-05-30T05:00:23.724352Z"
    }
   },
   "outputs": [],
   "source": [
    "net = InCoFCNet().to(Device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "base_optimizer = torch.optim.Adam\n",
    "optimizer = SAM(net.parameters(), rho=0.1, base_optimizer=base_optimizer,lr=1e-3,adaptive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a81bc956f5ec67ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:13:28.089304Z",
     "start_time": "2025-05-30T05:00:24.228226Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 1.049 Classification loss:0.705 angle_grad:-0.031 shift_y_grad:0.000 scale_grad:25.249\n",
      "[1,   600] loss: 0.560 Classification loss:0.546 angle_grad:0.000 shift_y_grad:0.077 scale_grad:38.427\n",
      "[1,   900] loss: 0.430 Classification loss:0.333 angle_grad:0.007 shift_y_grad:0.168 scale_grad:2.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\GPU_Pytorchpy39\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 10000 test images: 89.9 %\n",
      "[2,   300] loss: 0.353 Classification loss:0.367 angle_grad:-0.016 shift_y_grad:0.363 scale_grad:-0.294\n",
      "[2,   600] loss: 0.313 Classification loss:0.389 angle_grad:0.004 shift_y_grad:0.124 scale_grad:0.483\n",
      "[2,   900] loss: 0.288 Classification loss:0.240 angle_grad:0.000 shift_y_grad:0.318 scale_grad:2.113\n",
      "Accuracy 10000 test images: 92.87 %\n",
      "[3,   300] loss: 0.253 Classification loss:0.256 angle_grad:0.023 shift_y_grad:0.148 scale_grad:0.960\n",
      "[3,   600] loss: 0.242 Classification loss:0.305 angle_grad:0.022 shift_y_grad:0.079 scale_grad:1.924\n",
      "[3,   900] loss: 0.227 Classification loss:0.210 angle_grad:0.010 shift_y_grad:0.238 scale_grad:0.593\n",
      "Accuracy 10000 test images: 94.13 %\n",
      "[4,   300] loss: 0.207 Classification loss:0.198 angle_grad:0.010 shift_y_grad:0.049 scale_grad:0.793\n",
      "[4,   600] loss: 0.199 Classification loss:0.260 angle_grad:-0.002 shift_y_grad:0.013 scale_grad:0.619\n",
      "[4,   900] loss: 0.194 Classification loss:0.195 angle_grad:0.005 shift_y_grad:0.116 scale_grad:0.405\n",
      "Accuracy 10000 test images: 94.75 %\n",
      "[5,   300] loss: 0.176 Classification loss:0.170 angle_grad:0.006 shift_y_grad:0.000 scale_grad:2.167\n",
      "[5,   600] loss: 0.174 Classification loss:0.244 angle_grad:-0.008 shift_y_grad:0.000 scale_grad:0.910\n",
      "[5,   900] loss: 0.165 Classification loss:0.200 angle_grad:-0.005 shift_y_grad:0.070 scale_grad:-0.111\n",
      "Accuracy 10000 test images: 95.47 %\n",
      "[6,   300] loss: 0.156 Classification loss:0.137 angle_grad:0.005 shift_y_grad:0.000 scale_grad:0.849\n",
      "[6,   600] loss: 0.152 Classification loss:0.205 angle_grad:-0.034 shift_y_grad:0.000 scale_grad:1.326\n",
      "[6,   900] loss: 0.150 Classification loss:0.130 angle_grad:0.013 shift_y_grad:0.000 scale_grad:4.999\n",
      "Accuracy 10000 test images: 95.85 %\n",
      "[7,   300] loss: 0.137 Classification loss:0.106 angle_grad:-0.003 shift_y_grad:0.000 scale_grad:1.648\n",
      "[7,   600] loss: 0.137 Classification loss:0.208 angle_grad:0.006 shift_y_grad:0.056 scale_grad:0.431\n",
      "[7,   900] loss: 0.134 Classification loss:0.164 angle_grad:-0.001 shift_y_grad:0.000 scale_grad:-1.631\n",
      "Accuracy 10000 test images: 96.13 %\n",
      "[8,   300] loss: 0.123 Classification loss:0.112 angle_grad:-0.013 shift_y_grad:0.024 scale_grad:2.260\n",
      "[8,   600] loss: 0.125 Classification loss:0.146 angle_grad:-0.006 shift_y_grad:0.067 scale_grad:3.063\n",
      "[8,   900] loss: 0.122 Classification loss:0.104 angle_grad:0.014 shift_y_grad:0.042 scale_grad:5.058\n",
      "Accuracy 10000 test images: 96.37 %\n",
      "[9,   300] loss: 0.111 Classification loss:0.126 angle_grad:0.024 shift_y_grad:0.049 scale_grad:0.432\n",
      "[9,   600] loss: 0.113 Classification loss:0.192 angle_grad:-0.015 shift_y_grad:0.054 scale_grad:0.654\n",
      "[9,   900] loss: 0.114 Classification loss:0.114 angle_grad:0.004 shift_y_grad:0.066 scale_grad:6.142\n",
      "Accuracy 10000 test images: 96.53 %\n",
      "[10,   300] loss: 0.104 Classification loss:0.088 angle_grad:-0.011 shift_y_grad:0.016 scale_grad:0.116\n",
      "[10,   600] loss: 0.108 Classification loss:0.162 angle_grad:0.000 shift_y_grad:0.017 scale_grad:1.843\n",
      "[10,   900] loss: 0.106 Classification loss:0.085 angle_grad:0.001 shift_y_grad:0.050 scale_grad:4.571\n",
      "Accuracy 10000 test images: 96.73 %\n",
      "Finished Training\n",
      "W noise Accuracy 10000 test images: 96.73 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SAT\"\"\"\n",
    "scale = 1.0\n",
    "angle = 0.0\n",
    "shift_y = 0.0\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "        inputs = inputs.view(inputs.size(0), -1).to(Device)  # 将输入数据展平\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        scale_init = scale\n",
    "        angle_init = angle\n",
    "        shift_y_init = shift_y\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #### Perturbation and update non-differentiable parameters\n",
    "        if i % 3 == 0:\n",
    "            perturb_ang = (torch.clamp(torch.rand(1)*2.0,min=0.0,max=2.0)).to(Device)\n",
    "            perturb_ang_np = perturb_ang.cpu().detach().numpy()\n",
    "            angle = float(angle + perturb_ang)\n",
    "        if i % 3 == 1:\n",
    "            perturb_shif = (torch.clamp(torch.rand(1)*2.0,min=0.0,max=2.0)).to(Device)\n",
    "            perturb_shif_np = perturb_shif.cpu().detach().numpy()\n",
    "            shift_y = float(shift_y + perturb_shif)\n",
    "        if i % 3 == 2:\n",
    "            perturb_scal = (torch.clamp(torch.rand(1)*0.1,min=0,max=0.1)).to(Device)\n",
    "            perturb_scal_np = perturb_scal.cpu().detach().numpy()\n",
    "            scale = float(scale + perturb_scal)           \n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss_new = criterion(outputs, labels) \n",
    "        if i % 3 == 0:\n",
    "            angle_grad = (loss_new - loss)/perturb_ang ### 计算梯度\n",
    "        if i % 3 == 1:\n",
    "            shift_y_grad = (loss_new - loss)/perturb_shif ### 计算梯度\n",
    "        if i % 3 == 2:\n",
    "            scale_grad = (loss_new - loss)/perturb_scal ### 计算梯度\n",
    "\n",
    "        if i % 3 == 0:\n",
    "            angle_ascent = angle_grad ### Normalize grad\n",
    "            angle = angle + angle_ascent * 50.0\n",
    "            angle = float(angle.data.detach().cpu().numpy()[0]) \n",
    "        if i % 3 == 1:\n",
    "            shift_y_ascent = shift_y_grad ### Normalize grad\n",
    "            shift_y = shift_y + shift_y_ascent * 50.0\n",
    "            shift_y = float(shift_y.data.detach().cpu().numpy()[0])  \n",
    "        if i % 3 == 2:\n",
    "            scale_ascent = scale_grad ### Normalize grad        \n",
    "            scale = scale + scale_ascent * 0.001\n",
    "            scale = float(scale.data.detach().cpu().numpy()[0])\n",
    "            scale = np.clip(scale,1,1.1)                           \n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "        \n",
    "        outputs_sam = net(inputs)\n",
    "        loss_sam = criterion(outputs_sam, labels)\n",
    "        loss_sam.backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        \n",
    "        scale = scale_init\n",
    "        angle = angle_init\n",
    "        shift_y = shift_y_init\n",
    "              \n",
    "        running_loss += loss.item()\n",
    "        if i % 300 == 299:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 300:.3f} Classification loss:{loss.cpu().detach().numpy():.3f} angle_grad:{angle_grad.cpu().detach().numpy()[0]:.3f} shift_y_grad:{shift_y_grad.cpu().detach().numpy()[0]:.3f} scale_grad:{scale_grad.cpu().detach().numpy()[0]:.3f}')           \n",
    "            running_loss = 0.0\n",
    "    net.apply_constraints()\n",
    "    scheduler.step()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "            inputs = inputs.view(inputs.size(0), -1) \n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(inputs)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy 10000 test images: {100 * correct / total} %')\n",
    "print('Finished Training')\n",
    "y_pred = []\n",
    "t_pred = []\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "    inputs = inputs.view(-1, 784)\n",
    "    # calculate outputs by running images through the network\n",
    "    outputs = net(inputs)\n",
    "    # the class with the highest energy is what we choose as prediction\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    y = predicted.view(-1).cpu().detach().numpy()\n",
    "    t = labels.view(-1).cpu().detach().numpy()\n",
    "    for i in range(len(predicted)):\n",
    "        y_pred.append(y[i])\n",
    "        t_pred.append(t[i])\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print(f'W noise Accuracy 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9555fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"SAT\"\"\"\n",
    "# scale = 1.0\n",
    "# angle = 0.0\n",
    "# shift_y = 0.0\n",
    "\n",
    "# for epoch in range(3):  # loop over the dataset multiple times\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(trainloader, 0):\n",
    "#         # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "#         inputs = inputs.view(inputs.size(0), -1).to(Device)  # 将输入数据展平\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         scale_init = scale\n",
    "#         angle_init = angle\n",
    "#         shift_y_init = shift_y\n",
    "        \n",
    "#         outputs = net(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "        \n",
    "#         #### Perturbation and update non-differentiable parameters\n",
    "#         # if i % 2 == 0:\n",
    "#         perturb_ang = (torch.clamp(torch.rand(1)*3.0,min=0.0,max=3.0)).to(Device)\n",
    "#         perturb_ang_np = perturb_ang.cpu().detach().numpy()\n",
    "#         angle = float(angle + perturb_ang)\n",
    "#         # if i % 2 == 1:\n",
    "#         perturb_shif = (torch.clamp(torch.rand(1)*3.0,min=0.0,max=3.0)).to(Device)\n",
    "#         perturb_shif_np = perturb_shif.cpu().detach().numpy()\n",
    "#         shift_y = float(shift_y + perturb_shif)      \n",
    "\n",
    "#         outputs = net(inputs)\n",
    "\n",
    "#         loss_new = criterion(outputs, labels) \n",
    "#         # if i % 2 == 0:\n",
    "#         angle_grad = (loss_new - loss)/perturb_ang ### 计算梯度\n",
    "#         # if i % 2 == 1:\n",
    "#         shift_y_grad = (loss_new - loss)/perturb_shif ### 计算梯度\n",
    "\n",
    "#         # if i % 2 == 0:\n",
    "#         angle_ascent = angle_grad ### Normalize grad\n",
    "#         angle = angle + angle_ascent * 0.8\n",
    "#         angle = float(angle.data.detach().cpu().numpy()[0]) \n",
    "#         # if i % 2 == 1:\n",
    "#         shift_y_ascent = shift_y_grad ### Normalize grad\n",
    "#         shift_y = shift_y + shift_y_ascent * 0.8\n",
    "#         shift_y = float(shift_y.data.detach().cpu().numpy()[0])                      \n",
    "        \n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.first_step(zero_grad=True)\n",
    "        \n",
    "#         outputs_sam = net(inputs)\n",
    "#         loss_sam = criterion(outputs_sam, labels)\n",
    "#         loss_sam.backward()\n",
    "#         optimizer.second_step(zero_grad=True)\n",
    "        \n",
    "#         scale = scale_init\n",
    "#         angle = angle_init\n",
    "#         shift_y = shift_y_init\n",
    "              \n",
    "#         running_loss += loss.item()\n",
    "#         if i % 300 == 299:    # print every 2000 mini-batches\n",
    "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 300:.3f} Classification loss:{loss.cpu().detach().numpy():.3f} angle_grad:{angle_grad.cpu().detach().numpy()[0]:.3f} shift_y_grad:{shift_y_grad.cpu().detach().numpy()[0]:.3f}')           \n",
    "#             running_loss = 0.0\n",
    "#     net.apply_constraints()\n",
    "#     scheduler.step()\n",
    "#     total = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data in testloader:\n",
    "#             inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "#             inputs = inputs.view(inputs.size(0), -1) \n",
    "#             # calculate outputs by running images through the network\n",
    "#             outputs = net(inputs)\n",
    "#             # the class with the highest energy is what we choose as prediction\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#     print(f'Accuracy 10000 test images: {100 * correct / total} %')\n",
    "# print('Finished Training')\n",
    "# y_pred = []\n",
    "# t_pred = []\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# for data in testloader:\n",
    "#     inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "#     inputs = inputs.view(-1, 784)\n",
    "#     # calculate outputs by running images through the network\n",
    "#     outputs = net(inputs)\n",
    "#     # the class with the highest energy is what we choose as prediction\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     y = predicted.view(-1).cpu().detach().numpy()\n",
    "#     t = labels.view(-1).cpu().detach().numpy()\n",
    "#     for i in range(len(predicted)):\n",
    "#         y_pred.append(y[i])\n",
    "#         t_pred.append(t[i])\n",
    "#     total += labels.size(0)\n",
    "#     correct += (predicted == labels).sum().item()\n",
    "# print(f'W noise Accuracy 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1625f872c3297ecf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:13:28.099545Z",
     "start_time": "2025-05-30T05:13:28.089304Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net_sam=net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48519eac6a567546",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:13:30.820945Z",
     "start_time": "2025-05-30T05:13:30.813188Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Define NN class\"\"\"\n",
    "class InCoFCNet_test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InCoFCNet_test, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 144)\n",
    "        self.fc2 = nn.Linear(144, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = f_wn_1(x,self.fc1.weight.t())+self.fc1.bias\n",
    "        x = F.sigmoid(x)\n",
    "        x = f_wn_2(x,self.fc2.weight.t())+self.fc2.bias\n",
    "        return x\n",
    "    \n",
    "    def apply_constraints(self):\n",
    "        self.fc1.weight.data = torch.clamp(self.fc1.weight.data,-1,1)        \n",
    "        self.fc2.weight.data = torch.clamp(self.fc2.weight.data,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cede2b319e10491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:13:31.759313Z",
     "start_time": "2025-05-30T05:13:31.749617Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# net_test=InCoFCNet_test()\n",
    "# net_test.fc1=net_ref.fc1\n",
    "# net_test.fc2=net_ref.fc2\n",
    "net_test_sam=InCoFCNet_test()\n",
    "net_test_sam.fc1=net_sam.fc1\n",
    "net_test_sam.fc2=net_sam.fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5e0c3048014488f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T03:15:14.568106Z",
     "start_time": "2025-05-30T03:15:14.558839Z"
    }
   },
   "outputs": [],
   "source": [
    "# PATH = 'Training Results/standard_bp.pth'\n",
    "# torch.save(net_test.state_dict(), PATH)\n",
    "# PATH = ''\n",
    "PATH = 'Training Results/sat-angle shift scale-v4.pth'\n",
    "torch.save(net_test_sam.state_dict(), PATH)\n",
    "PATH = ''\n",
    "# PATH = 'Training Results/sat-angle shift.pth'\n",
    "# torch.save(net_test_sam.state_dict(), PATH)\n",
    "# PATH = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f286be0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
