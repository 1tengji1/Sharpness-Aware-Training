{
 "cells": [
  {
   "cell_type": "code",
   "id": "31e98cb42e3a8796",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T02:52:30.108074Z",
     "start_time": "2025-07-04T02:52:27.571557Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\GPU_Pytorchpy39\\lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "9cdd77e8d6f4a74a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T02:52:30.717125Z",
     "start_time": "2025-07-04T02:52:30.661166Z"
    }
   },
   "source": [
    "transform = transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "                                   torchvision.transforms.Normalize(\n",
    "                                       (0.1307,), (0.3081,))])\n",
    "\n",
    "batch_size = 6000\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "8a547e8fa24954d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T02:52:37.143395Z",
     "start_time": "2025-07-04T02:52:31.176583Z"
    }
   },
   "source": [
    "from mnist import *\n",
    "from viz import *\n",
    "\n",
    "import torch\n",
    "from torch.nn import Sequential, Module, CrossEntropyLoss\n",
    "from torch.nn.functional import normalize\n",
    "import numpy as np\n",
    "from neurophoxTorch.torch import RMTorch\n",
    "from scipy.stats import unitary_group\n",
    "from tqdm import tqdm_notebook as pbar\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "def rc_mul(real: torch.Tensor, comp: torch.Tensor):\n",
    "    return real.unsqueeze(dim=0) * comp\n",
    "\n",
    "\n",
    "def cc_mul(comp1: torch.Tensor, comp2: torch.Tensor) -> torch.Tensor:\n",
    "    real = comp1[0] * comp2[0] - comp1[1] * comp2[1]\n",
    "    comp = comp1[0] * comp2[1] + comp1[1] * comp2[0]\n",
    "    return torch.stack((real, comp), dim=0)\n",
    "\n",
    "def phasor(real: torch.Tensor):\n",
    "    return torch.stack((real.cos(), real.sin()), dim=0)\n",
    "\n",
    "\n",
    "def cnorm(comp: torch.Tensor):\n",
    "    return (comp[0] ** 2 + comp[1] ** 2).sqrt()\n",
    "\n",
    "\n",
    "def cnormsq(comp: torch.Tensor):\n",
    "    return comp[0] ** 2 + comp[1] ** 2\n",
    "\n",
    "\n",
    "def to_complex_t(nparray: np.ndarray):\n",
    "    return torch.stack((torch.as_tensor(nparray.real),\n",
    "                        torch.as_tensor(nparray.imag)), dim=0)\n",
    "\n",
    "\n",
    "class ElectroopticNonlinearity(Module):\n",
    "    def __init__(self, alpha: float=0.1, g: float=0.05 * np.pi, phi_b: float=np.pi):\n",
    "        super(ElectroopticNonlinearity, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.g = g\n",
    "        self.phi_b = phi_b\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        phase = 0.5 * self.g * cnormsq(inputs) + 0.5 * self.phi_b\n",
    "        return np.sqrt(1 - self.alpha) * cc_mul(rc_mul(phase.cos(), phasor(-phase)), inputs)\n",
    "\n",
    "\n",
    "class CNormSq(Module):\n",
    "    def __init__(self, normed=True):\n",
    "        super(CNormSq, self).__init__()\n",
    "        self.normed = normed\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return normalize(cnormsq(inputs), dim=1) if self.normed else cnormsq(inputs)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ResearchProject\\PNNRobustOptimization\\OpenSourceCodes\\System3-MZI Mesh\\mnist.py:2: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.5)\n",
      "  import scipy as sp\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "40f6bec223401616",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T02:52:38.953470Z",
     "start_time": "2025-07-04T02:52:37.605825Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 64)\n",
    "        self.norm1 = nn.BatchNorm2d(6)\n",
    "        self.norm2 = nn.BatchNorm2d(16)\n",
    "        self.norm3 = nn.BatchNorm1d(120)\n",
    "        self.layer1 = RMTorch(64, phase_error = 0, phase_error_files = None,bs_error=0,bs_error_files = None)\n",
    "        self.output = CNormSq()\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = F.max_pool2d(F.relu(self.norm1(self.conv1(x))), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.norm2(self.conv2(x))), (2, 2))\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.fc1(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.stack((x, torch.zeros(x.shape, dtype=torch.float32, device=x.device)), dim=0)\n",
    "        x,_,_,_ = self.layer1(x)\n",
    "        x = self.output(x)\n",
    "        self.at_sensor_intensity = x\n",
    "        return self.at_sensor_intensity[:,:10]\n",
    "    \n",
    "    def phy_forward(self,x):\n",
    "        self.in_outs_phy = []\n",
    "        with torch.no_grad():\n",
    "            x = F.max_pool2d(F.relu(self.norm1(self.conv1(x))), (2, 2))\n",
    "            x = F.max_pool2d(F.relu(self.norm2(self.conv2(x))), (2, 2))\n",
    "            x = x.view(x.size(0), -1) \n",
    "            x = self.fc1(x)\n",
    "            x = self.norm3(x)\n",
    "            x = self.fc2(x)\n",
    "            x = torch.stack((x, torch.zeros(x.shape, dtype=torch.float32, device=x.device)), dim=0)\n",
    "            x, _, _, _ = self.layer1(x)\n",
    "            x = self.output(x)\n",
    "            self.at_sensor_intensity_phy = x\n",
    "        return self.at_sensor_intensity_phy[:,:10]    \n",
    "    \n",
    "    def phy_replace_sim(self):\n",
    "        # PAT: replace the output\n",
    "        with torch.no_grad():\n",
    "            self.at_sensor_intensity.data.copy_(self.at_sensor_intensity_phy.data)    \n",
    "\n",
    "    def apply_constraints(self):\n",
    "        self.conv1.cuda().weight.data = torch.clamp(self.conv1.cuda().weight.data, -1, 1)\n",
    "        self.conv2.cuda().weight.data = torch.clamp(self.conv2.cuda().weight.data, -1, 1)\n",
    "        self.fc1.cuda().weight.data = torch.clamp(self.fc1.cuda().weight.data, -1, 1)\n",
    "        self.fc2.cuda().weight.data = torch.clamp(self.fc2.cuda().weight.data, -1, 1)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "net = LeNet5()\n",
    "net.to(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=64, bias=True)\n",
       "  (norm1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm3): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): RMTorch()\n",
       "  (output): CNormSq()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "6818a899443fa91e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:06:16.784843Z",
     "start_time": "2025-06-05T09:06:16.774431Z"
    }
   },
   "source": [
    "### Store the ideal parameters\n",
    "### nenn,nepn,nenp,nepp indicate the parameters without fabrication errors\n",
    "### nenn,nepn,nenp,nepp indicate the parameters with    fabrication errors\n",
    "[nenn, nepn, nenp, nepp], [enn, epn, enp, epp] = net.layer1.mesh_model.mzi_error_tensors()\n",
    "[nenn_init, nepn_init, nenp_init, nepp_init] = [nenn, nepn, nenp, nepp] ### And we store the nenn... first"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "f72ff67c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:06:17.567617Z",
     "start_time": "2025-06-05T09:06:17.560280Z"
    }
   },
   "source": [
    "bsE_scale = 0.15\n",
    "phaseE_scale = 0.15"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "26d47a775af1da60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:06:18.011183Z",
     "start_time": "2025-06-05T09:06:17.990799Z"
    }
   },
   "source": [
    "### Introduce manufacturing errors\n",
    "net.layer1.mesh_model.bs_error = bsE_scale\n",
    "[nenn, nepn, nenp, nepp], [enn, epn, enp, epp] = net.layer1.mesh_model.mzi_error_tensors()\n",
    "net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                    torch.as_tensor(nenn, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepn, dtype=torch.float32).cuda(), \\\n",
    "                    torch.as_tensor(nenp, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepp, dtype=torch.float32).cuda()\n",
    "net.layer1.enn, net.layer1.epn, net.layer1.enp, net.layer1.epp = \\\n",
    "                    torch.as_tensor(enn, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(epn, dtype=torch.float32).cuda(), \\\n",
    "                    torch.as_tensor(enp, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(epp, dtype=torch.float32).cuda()\n",
    "\n",
    "### You can save the errors and directely load if you need\n",
    "# np.save('.\\MZI_Error/N64/bsE'+str(bsE_scale)+'/enn.npy', enn)\n",
    "# np.save('.\\MZI_Error/N64/bsE'+str(bsE_scale)+'/epn.npy', epn)\n",
    "# np.save('.\\MZI_Error/N64/bsE'+str(bsE_scale)+'/enp.npy', enp)\n",
    "# np.save('.\\MZI_Error/N64/bsE'+str(bsE_scale)+'/epp.npy', epp)\n",
    "enn = np.load('.\\MZI_Error/N64/bsE'+str(bsE_scale)+'/enn.npy')\n",
    "epn = np.load('.\\MZI_Error/N64/bsE'+str(bsE_scale)+'/epn.npy')\n",
    "enp = np.load('./MZI_Error/N64/bsE'+str(bsE_scale)+'/enp.npy')\n",
    "epp = np.load('./MZI_Error/N64/bsE'+str(bsE_scale)+'/epp.npy')\n",
    "\n",
    "[nenn_n, nepn_n, nenp_n, nepp_n] = [enn, epn, enp, epp] ### Here, we copy the generated errors to nenn..."
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "1cef4f381b3e7b0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:06:19.339990Z",
     "start_time": "2025-06-05T09:06:19.329866Z"
    }
   },
   "source": [
    "### Introduce phase errors\n",
    "b0_theta_error = torch.randn(net.layer1.theta.shape).cuda() * phaseE_scale\n",
    "b0_phi_error = torch.randn(net.layer1.phi.shape).cuda() * phaseE_scale\n",
    "\n",
    "### You can save the errors and directely load if you need\n",
    "# np.save('.\\MZI_Error/N64/phaseE'+str(phaseE_scale)+'/theta.npy', b0_theta_error.cpu().detach().numpy())\n",
    "# np.save('.\\MZI_Error/N64/phaseE'+str(phaseE_scale)+'/phi.npy', b0_phi_error.cpu().detach().numpy())\n",
    "b0_theta_error = np.load('.\\MZI_Error/N64/phaseE'+str(phaseE_scale)+'/theta.npy')\n",
    "b0_phi_error = np.load('.\\MZI_Error/N64/phaseE'+str(phaseE_scale)+'/phi.npy')\n",
    "b0_theta_error = torch.tensor(b0_theta_error).to(device)\n",
    "b0_phi_error = torch.tensor(b0_phi_error).to(device)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:07:59.363567Z",
     "start_time": "2025-06-05T09:07:59.357561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "def set_random_seed(seed: int = 42, deterministic: bool = True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)          \n",
    "        torch.cuda.manual_seed_all(seed)     \n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "set_random_seed(seed=42)"
   ],
   "id": "1e2b002480a33701",
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "84d2fb33",
   "metadata": {},
   "source": [
    "Now we start to compare different methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82a7b6",
   "metadata": {},
   "source": [
    "### 01-Standard BP"
   ]
  },
  {
   "cell_type": "code",
   "id": "7205bc60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:08:02.425481Z",
     "start_time": "2025-06-05T09:08:02.404797Z"
    }
   },
   "source": [
    "import torch.optim as optim\n",
    "net = LeNet5()\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 400, gamma = 0.5)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "ee5632a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:13:58.977046Z",
     "start_time": "2025-06-05T09:08:02.907316Z"
    }
   },
   "source": [
    "import time\n",
    "net.to(device)\n",
    "start = time.time()\n",
    "for epoch in range(40):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs_sim = net(inputs)\n",
    "        loss0 = criterion(outputs_sim, labels)\n",
    "        loss = loss0\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        net.apply_constraints()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2 == 1:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2:.3f} Classification loss:{loss0.cpu().detach().numpy():.3f}')\n",
    "            running_loss = 0.0\n",
    "    scheduler.step()\n",
    "    if epoch % 10 == 9:    # print every 2000 mini-batches\n",
    "        print(f'epoch:{epoch}')\n",
    "        net.to(device)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                # calculate outputs by running images through the network\n",
    "                net.layer1.theta.data = net.layer1.theta.data + b0_theta_error\n",
    "                net.layer1.phi.data = net.layer1.phi.data + b0_phi_error\n",
    "                net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                        torch.as_tensor(nenn_n, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepn_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nenp_n, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepp_n, dtype=torch.float32).cuda()                \n",
    "                outputs = net.phy_forward(inputs)\n",
    "                net.layer1.theta.data = net.layer1.theta.data - b0_theta_error\n",
    "                net.layer1.phi.data = net.layer1.phi.data - b0_phi_error  \n",
    "                net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                        torch.as_tensor(nenn_init, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepn_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nenp_init, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepp_init, dtype=torch.float32).cuda()   \n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print(f'Accuracy 10000 test images: {100 * correct / total} %')\n",
    "        accu_wo_n = 100 * correct / total\n",
    "print('Finished Training')\n",
    "end = time.time()\n",
    "print(end-start)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     2] loss: 2.303 Classification loss:2.294\n",
      "[1,     4] loss: 2.204 Classification loss:2.163\n",
      "[1,     6] loss: 2.050 Classification loss:2.015\n",
      "[1,     8] loss: 1.928 Classification loss:1.903\n",
      "[1,    10] loss: 1.855 Classification loss:1.839\n",
      "[2,     2] loss: 1.803 Classification loss:1.790\n",
      "[2,     4] loss: 1.761 Classification loss:1.754\n",
      "[2,     6] loss: 1.737 Classification loss:1.731\n",
      "[2,     8] loss: 1.716 Classification loss:1.714\n",
      "[2,    10] loss: 1.700 Classification loss:1.696\n",
      "[3,     2] loss: 1.682 Classification loss:1.678\n",
      "[3,     4] loss: 1.671 Classification loss:1.670\n",
      "[3,     6] loss: 1.662 Classification loss:1.658\n",
      "[3,     8] loss: 1.651 Classification loss:1.648\n",
      "[3,    10] loss: 1.644 Classification loss:1.639\n",
      "[4,     2] loss: 1.636 Classification loss:1.636\n",
      "[4,     4] loss: 1.628 Classification loss:1.627\n",
      "[4,     6] loss: 1.623 Classification loss:1.623\n",
      "[4,     8] loss: 1.618 Classification loss:1.617\n",
      "[4,    10] loss: 1.613 Classification loss:1.609\n",
      "[5,     2] loss: 1.606 Classification loss:1.603\n",
      "[5,     4] loss: 1.603 Classification loss:1.602\n",
      "[5,     6] loss: 1.599 Classification loss:1.598\n",
      "[5,     8] loss: 1.598 Classification loss:1.596\n",
      "[5,    10] loss: 1.594 Classification loss:1.592\n",
      "[6,     2] loss: 1.592 Classification loss:1.590\n",
      "[6,     4] loss: 1.587 Classification loss:1.587\n",
      "[6,     6] loss: 1.581 Classification loss:1.581\n",
      "[6,     8] loss: 1.581 Classification loss:1.582\n",
      "[6,    10] loss: 1.579 Classification loss:1.577\n",
      "[7,     2] loss: 1.579 Classification loss:1.577\n",
      "[7,     4] loss: 1.575 Classification loss:1.575\n",
      "[7,     6] loss: 1.573 Classification loss:1.572\n",
      "[7,     8] loss: 1.569 Classification loss:1.570\n",
      "[7,    10] loss: 1.568 Classification loss:1.564\n",
      "[8,     2] loss: 1.568 Classification loss:1.565\n",
      "[8,     4] loss: 1.565 Classification loss:1.566\n",
      "[8,     6] loss: 1.564 Classification loss:1.562\n",
      "[8,     8] loss: 1.563 Classification loss:1.563\n",
      "[8,    10] loss: 1.561 Classification loss:1.560\n",
      "[9,     2] loss: 1.560 Classification loss:1.560\n",
      "[9,     4] loss: 1.558 Classification loss:1.558\n",
      "[9,     6] loss: 1.558 Classification loss:1.557\n",
      "[9,     8] loss: 1.556 Classification loss:1.555\n",
      "[9,    10] loss: 1.555 Classification loss:1.556\n",
      "[10,     2] loss: 1.554 Classification loss:1.554\n",
      "[10,     4] loss: 1.552 Classification loss:1.553\n",
      "[10,     6] loss: 1.552 Classification loss:1.550\n",
      "[10,     8] loss: 1.550 Classification loss:1.550\n",
      "[10,    10] loss: 1.552 Classification loss:1.551\n",
      "epoch:9\n",
      "Accuracy 10000 test images: 62.04 %\n",
      "[11,     2] loss: 1.550 Classification loss:1.550\n",
      "[11,     4] loss: 1.548 Classification loss:1.549\n",
      "[11,     6] loss: 1.546 Classification loss:1.547\n",
      "[11,     8] loss: 1.546 Classification loss:1.545\n",
      "[11,    10] loss: 1.548 Classification loss:1.547\n",
      "[12,     2] loss: 1.545 Classification loss:1.548\n",
      "[12,     4] loss: 1.545 Classification loss:1.545\n",
      "[12,     6] loss: 1.543 Classification loss:1.542\n",
      "[12,     8] loss: 1.544 Classification loss:1.545\n",
      "[12,    10] loss: 1.541 Classification loss:1.541\n",
      "[13,     2] loss: 1.543 Classification loss:1.541\n",
      "[13,     4] loss: 1.542 Classification loss:1.542\n",
      "[13,     6] loss: 1.540 Classification loss:1.540\n",
      "[13,     8] loss: 1.541 Classification loss:1.540\n",
      "[13,    10] loss: 1.537 Classification loss:1.541\n",
      "[14,     2] loss: 1.539 Classification loss:1.537\n",
      "[14,     4] loss: 1.538 Classification loss:1.535\n",
      "[14,     6] loss: 1.538 Classification loss:1.538\n",
      "[14,     8] loss: 1.536 Classification loss:1.535\n",
      "[14,    10] loss: 1.538 Classification loss:1.538\n",
      "[15,     2] loss: 1.534 Classification loss:1.534\n",
      "[15,     4] loss: 1.536 Classification loss:1.537\n",
      "[15,     6] loss: 1.536 Classification loss:1.534\n",
      "[15,     8] loss: 1.534 Classification loss:1.534\n",
      "[15,    10] loss: 1.536 Classification loss:1.536\n",
      "[16,     2] loss: 1.534 Classification loss:1.535\n",
      "[16,     4] loss: 1.533 Classification loss:1.531\n",
      "[16,     6] loss: 1.533 Classification loss:1.532\n",
      "[16,     8] loss: 1.533 Classification loss:1.533\n",
      "[16,    10] loss: 1.532 Classification loss:1.531\n",
      "[17,     2] loss: 1.532 Classification loss:1.532\n",
      "[17,     4] loss: 1.532 Classification loss:1.530\n",
      "[17,     6] loss: 1.531 Classification loss:1.532\n",
      "[17,     8] loss: 1.531 Classification loss:1.530\n",
      "[17,    10] loss: 1.529 Classification loss:1.527\n",
      "[18,     2] loss: 1.529 Classification loss:1.529\n",
      "[18,     4] loss: 1.531 Classification loss:1.530\n",
      "[18,     6] loss: 1.529 Classification loss:1.528\n",
      "[18,     8] loss: 1.530 Classification loss:1.530\n",
      "[18,    10] loss: 1.528 Classification loss:1.528\n",
      "[19,     2] loss: 1.528 Classification loss:1.528\n",
      "[19,     4] loss: 1.528 Classification loss:1.528\n",
      "[19,     6] loss: 1.529 Classification loss:1.527\n",
      "[19,     8] loss: 1.527 Classification loss:1.527\n",
      "[19,    10] loss: 1.526 Classification loss:1.524\n",
      "[20,     2] loss: 1.527 Classification loss:1.528\n",
      "[20,     4] loss: 1.526 Classification loss:1.525\n",
      "[20,     6] loss: 1.526 Classification loss:1.527\n",
      "[20,     8] loss: 1.525 Classification loss:1.524\n",
      "[20,    10] loss: 1.527 Classification loss:1.527\n",
      "epoch:19\n",
      "Accuracy 10000 test images: 66.22 %\n",
      "[21,     2] loss: 1.526 Classification loss:1.526\n",
      "[21,     4] loss: 1.524 Classification loss:1.523\n",
      "[21,     6] loss: 1.524 Classification loss:1.522\n",
      "[21,     8] loss: 1.525 Classification loss:1.525\n",
      "[21,    10] loss: 1.525 Classification loss:1.524\n",
      "[22,     2] loss: 1.523 Classification loss:1.523\n",
      "[22,     4] loss: 1.523 Classification loss:1.522\n",
      "[22,     6] loss: 1.524 Classification loss:1.525\n",
      "[22,     8] loss: 1.523 Classification loss:1.525\n",
      "[22,    10] loss: 1.524 Classification loss:1.523\n",
      "[23,     2] loss: 1.524 Classification loss:1.522\n",
      "[23,     4] loss: 1.523 Classification loss:1.523\n",
      "[23,     6] loss: 1.522 Classification loss:1.520\n",
      "[23,     8] loss: 1.521 Classification loss:1.524\n",
      "[23,    10] loss: 1.521 Classification loss:1.521\n",
      "[24,     2] loss: 1.520 Classification loss:1.521\n",
      "[24,     4] loss: 1.524 Classification loss:1.524\n",
      "[24,     6] loss: 1.522 Classification loss:1.522\n",
      "[24,     8] loss: 1.520 Classification loss:1.520\n",
      "[24,    10] loss: 1.520 Classification loss:1.520\n",
      "[25,     2] loss: 1.519 Classification loss:1.518\n",
      "[25,     4] loss: 1.521 Classification loss:1.521\n",
      "[25,     6] loss: 1.522 Classification loss:1.522\n",
      "[25,     8] loss: 1.518 Classification loss:1.519\n",
      "[25,    10] loss: 1.520 Classification loss:1.519\n",
      "[26,     2] loss: 1.521 Classification loss:1.521\n",
      "[26,     4] loss: 1.517 Classification loss:1.519\n",
      "[26,     6] loss: 1.521 Classification loss:1.523\n",
      "[26,     8] loss: 1.520 Classification loss:1.519\n",
      "[26,    10] loss: 1.516 Classification loss:1.517\n",
      "[27,     2] loss: 1.519 Classification loss:1.519\n",
      "[27,     4] loss: 1.517 Classification loss:1.517\n",
      "[27,     6] loss: 1.519 Classification loss:1.518\n",
      "[27,     8] loss: 1.518 Classification loss:1.518\n",
      "[27,    10] loss: 1.518 Classification loss:1.519\n",
      "[28,     2] loss: 1.517 Classification loss:1.516\n",
      "[28,     4] loss: 1.518 Classification loss:1.518\n",
      "[28,     6] loss: 1.516 Classification loss:1.516\n",
      "[28,     8] loss: 1.517 Classification loss:1.518\n",
      "[28,    10] loss: 1.518 Classification loss:1.519\n",
      "[29,     2] loss: 1.517 Classification loss:1.519\n",
      "[29,     4] loss: 1.515 Classification loss:1.516\n",
      "[29,     6] loss: 1.516 Classification loss:1.515\n",
      "[29,     8] loss: 1.517 Classification loss:1.518\n",
      "[29,    10] loss: 1.516 Classification loss:1.514\n",
      "[30,     2] loss: 1.516 Classification loss:1.517\n",
      "[30,     4] loss: 1.515 Classification loss:1.515\n",
      "[30,     6] loss: 1.515 Classification loss:1.515\n",
      "[30,     8] loss: 1.516 Classification loss:1.517\n",
      "[30,    10] loss: 1.516 Classification loss:1.515\n",
      "epoch:29\n",
      "Accuracy 10000 test images: 67.84 %\n",
      "[31,     2] loss: 1.516 Classification loss:1.515\n",
      "[31,     4] loss: 1.513 Classification loss:1.513\n",
      "[31,     6] loss: 1.514 Classification loss:1.513\n",
      "[31,     8] loss: 1.515 Classification loss:1.514\n",
      "[31,    10] loss: 1.516 Classification loss:1.516\n",
      "[32,     2] loss: 1.514 Classification loss:1.513\n",
      "[32,     4] loss: 1.513 Classification loss:1.513\n",
      "[32,     6] loss: 1.514 Classification loss:1.516\n",
      "[32,     8] loss: 1.514 Classification loss:1.515\n",
      "[32,    10] loss: 1.515 Classification loss:1.515\n",
      "[33,     2] loss: 1.514 Classification loss:1.515\n",
      "[33,     4] loss: 1.514 Classification loss:1.514\n",
      "[33,     6] loss: 1.511 Classification loss:1.511\n",
      "[33,     8] loss: 1.513 Classification loss:1.513\n",
      "[33,    10] loss: 1.515 Classification loss:1.515\n",
      "[34,     2] loss: 1.512 Classification loss:1.512\n",
      "[34,     4] loss: 1.511 Classification loss:1.512\n",
      "[34,     6] loss: 1.513 Classification loss:1.511\n",
      "[34,     8] loss: 1.514 Classification loss:1.516\n",
      "[34,    10] loss: 1.514 Classification loss:1.515\n",
      "[35,     2] loss: 1.514 Classification loss:1.513\n",
      "[35,     4] loss: 1.513 Classification loss:1.513\n",
      "[35,     6] loss: 1.511 Classification loss:1.511\n",
      "[35,     8] loss: 1.512 Classification loss:1.512\n",
      "[35,    10] loss: 1.511 Classification loss:1.511\n",
      "[36,     2] loss: 1.512 Classification loss:1.513\n",
      "[36,     4] loss: 1.510 Classification loss:1.509\n",
      "[36,     6] loss: 1.512 Classification loss:1.512\n",
      "[36,     8] loss: 1.512 Classification loss:1.511\n",
      "[36,    10] loss: 1.511 Classification loss:1.510\n",
      "[37,     2] loss: 1.512 Classification loss:1.511\n",
      "[37,     4] loss: 1.510 Classification loss:1.510\n",
      "[37,     6] loss: 1.513 Classification loss:1.512\n",
      "[37,     8] loss: 1.510 Classification loss:1.510\n",
      "[37,    10] loss: 1.511 Classification loss:1.510\n",
      "[38,     2] loss: 1.511 Classification loss:1.509\n",
      "[38,     4] loss: 1.510 Classification loss:1.511\n",
      "[38,     6] loss: 1.510 Classification loss:1.510\n",
      "[38,     8] loss: 1.509 Classification loss:1.510\n",
      "[38,    10] loss: 1.511 Classification loss:1.513\n",
      "[39,     2] loss: 1.509 Classification loss:1.511\n",
      "[39,     4] loss: 1.511 Classification loss:1.511\n",
      "[39,     6] loss: 1.509 Classification loss:1.510\n",
      "[39,     8] loss: 1.509 Classification loss:1.509\n",
      "[39,    10] loss: 1.511 Classification loss:1.512\n",
      "[40,     2] loss: 1.510 Classification loss:1.509\n",
      "[40,     4] loss: 1.509 Classification loss:1.511\n",
      "[40,     6] loss: 1.509 Classification loss:1.509\n",
      "[40,     8] loss: 1.510 Classification loss:1.511\n",
      "[40,    10] loss: 1.508 Classification loss:1.508\n",
      "epoch:39\n",
      "Accuracy 10000 test images: 68.64 %\n",
      "Finished Training\n",
      "356.0590465068817\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "e8e272c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:13:58.987065Z",
     "start_time": "2025-06-05T09:13:58.977046Z"
    }
   },
   "source": [
    "PATH = './Training Results/01-Standard BP.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "PATH = ''"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "d802c812",
   "metadata": {},
   "source": [
    "### 02-PAT"
   ]
  },
  {
   "cell_type": "code",
   "id": "33757192",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:13:59.007577Z",
     "start_time": "2025-06-05T09:13:58.988569Z"
    }
   },
   "source": [
    "import torch.optim as optim\n",
    "net = LeNet5()\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 400, gamma = 0.5)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "351c0efa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:20:32.823443Z",
     "start_time": "2025-06-05T09:13:59.007577Z"
    }
   },
   "source": [
    "import time\n",
    "net.to(device)\n",
    "start = time.time()\n",
    "for epoch in range(40):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs_sim = net(inputs)\n",
    "        with torch.no_grad():\n",
    "            net.layer1.theta.data = net.layer1.theta.data + b0_theta_error\n",
    "            net.layer1.phi.data = net.layer1.phi.data + b0_phi_error\n",
    "            net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                    torch.as_tensor(nenn_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepn_n, dtype=torch.float32).cuda(), \\\n",
    "                    torch.as_tensor(nenp_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepp_n, dtype=torch.float32).cuda()\n",
    "            outputs_phy = net.phy_forward(inputs)\n",
    "            net.phy_replace_sim()\n",
    "            outputs_sim.data.copy_(outputs_phy.data)\n",
    "            net.layer1.theta.data = net.layer1.theta.data - b0_theta_error\n",
    "            net.layer1.phi.data = net.layer1.phi.data - b0_phi_error  \n",
    "            net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                    torch.as_tensor(nenn_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepn_init, dtype=torch.float32).cuda(), \\\n",
    "                    torch.as_tensor(nenp_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepp_init, dtype=torch.float32).cuda()            \n",
    "        \n",
    "        # loss0 = criterion(outputs, labels)\n",
    "        loss0 = criterion(outputs_sim, labels)\n",
    "        loss = loss0\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        net.apply_constraints()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2 == 1:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2:.3f} Classification loss:{loss0.cpu().detach().numpy():.3f}')\n",
    "            running_loss = 0.0\n",
    "    scheduler.step()\n",
    "    if epoch % 10 == 9:    # print every 2000 mini-batches\n",
    "        print(f'epoch:{epoch}')\n",
    "        net.to(device)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                # calculate outputs by running images through the network\n",
    "                net.layer1.theta.data = net.layer1.theta.data + b0_theta_error\n",
    "                net.layer1.phi.data = net.layer1.phi.data + b0_phi_error\n",
    "                net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                        torch.as_tensor(nenn_n, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepn_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nenp_n, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepp_n, dtype=torch.float32).cuda()                \n",
    "                outputs = net.phy_forward(inputs)\n",
    "                net.layer1.theta.data = net.layer1.theta.data - b0_theta_error\n",
    "                net.layer1.phi.data = net.layer1.phi.data - b0_phi_error  \n",
    "                net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                        torch.as_tensor(nenn_init, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepn_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nenp_init, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepp_init, dtype=torch.float32).cuda()   \n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print(f'Accuracy 10000 test images: {100 * correct / total} %')\n",
    "        accu_wo_n = 100 * correct / total\n",
    "print('Finished Training')\n",
    "end = time.time()\n",
    "print(end-start)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     2] loss: 2.291 Classification loss:2.285\n",
      "[1,     4] loss: 2.258 Classification loss:2.247\n",
      "[1,     6] loss: 2.226 Classification loss:2.218\n",
      "[1,     8] loss: 2.197 Classification loss:2.190\n",
      "[1,    10] loss: 2.180 Classification loss:2.175\n",
      "[2,     2] loss: 2.161 Classification loss:2.159\n",
      "[2,     4] loss: 2.147 Classification loss:2.143\n",
      "[2,     6] loss: 2.139 Classification loss:2.136\n",
      "[2,     8] loss: 2.128 Classification loss:2.129\n",
      "[2,    10] loss: 2.117 Classification loss:2.111\n",
      "[3,     2] loss: 2.108 Classification loss:2.109\n",
      "[3,     4] loss: 2.105 Classification loss:2.107\n",
      "[3,     6] loss: 2.098 Classification loss:2.096\n",
      "[3,     8] loss: 2.099 Classification loss:2.096\n",
      "[3,    10] loss: 2.092 Classification loss:2.093\n",
      "[4,     2] loss: 2.088 Classification loss:2.087\n",
      "[4,     4] loss: 2.082 Classification loss:2.083\n",
      "[4,     6] loss: 2.078 Classification loss:2.078\n",
      "[4,     8] loss: 2.074 Classification loss:2.073\n",
      "[4,    10] loss: 2.070 Classification loss:2.067\n",
      "[5,     2] loss: 2.069 Classification loss:2.067\n",
      "[5,     4] loss: 2.068 Classification loss:2.066\n",
      "[5,     6] loss: 2.065 Classification loss:2.065\n",
      "[5,     8] loss: 2.066 Classification loss:2.063\n",
      "[5,    10] loss: 2.058 Classification loss:2.057\n",
      "[6,     2] loss: 2.057 Classification loss:2.052\n",
      "[6,     4] loss: 2.057 Classification loss:2.059\n",
      "[6,     6] loss: 2.056 Classification loss:2.058\n",
      "[6,     8] loss: 2.055 Classification loss:2.055\n",
      "[6,    10] loss: 2.052 Classification loss:2.050\n",
      "[7,     2] loss: 2.050 Classification loss:2.050\n",
      "[7,     4] loss: 2.049 Classification loss:2.049\n",
      "[7,     6] loss: 2.050 Classification loss:2.053\n",
      "[7,     8] loss: 2.044 Classification loss:2.038\n",
      "[7,    10] loss: 2.044 Classification loss:2.044\n",
      "[8,     2] loss: 2.046 Classification loss:2.050\n",
      "[8,     4] loss: 2.041 Classification loss:2.040\n",
      "[8,     6] loss: 2.037 Classification loss:2.036\n",
      "[8,     8] loss: 2.038 Classification loss:2.040\n",
      "[8,    10] loss: 2.039 Classification loss:2.040\n",
      "[9,     2] loss: 2.040 Classification loss:2.040\n",
      "[9,     4] loss: 2.033 Classification loss:2.033\n",
      "[9,     6] loss: 2.029 Classification loss:2.024\n",
      "[9,     8] loss: 2.035 Classification loss:2.039\n",
      "[9,    10] loss: 2.036 Classification loss:2.037\n",
      "[10,     2] loss: 2.032 Classification loss:2.031\n",
      "[10,     4] loss: 2.033 Classification loss:2.034\n",
      "[10,     6] loss: 2.027 Classification loss:2.030\n",
      "[10,     8] loss: 2.027 Classification loss:2.026\n",
      "[10,    10] loss: 2.027 Classification loss:2.026\n",
      "epoch:9\n",
      "Accuracy 10000 test images: 66.96 %\n",
      "[11,     2] loss: 2.024 Classification loss:2.021\n",
      "[11,     4] loss: 2.028 Classification loss:2.027\n",
      "[11,     6] loss: 2.025 Classification loss:2.027\n",
      "[11,     8] loss: 2.021 Classification loss:2.019\n",
      "[11,    10] loss: 2.024 Classification loss:2.026\n",
      "[12,     2] loss: 2.024 Classification loss:2.023\n",
      "[12,     4] loss: 2.021 Classification loss:2.014\n",
      "[12,     6] loss: 2.017 Classification loss:2.016\n",
      "[12,     8] loss: 2.021 Classification loss:2.026\n",
      "[12,    10] loss: 2.023 Classification loss:2.018\n",
      "[13,     2] loss: 2.017 Classification loss:2.017\n",
      "[13,     4] loss: 2.020 Classification loss:2.024\n",
      "[13,     6] loss: 2.013 Classification loss:2.014\n",
      "[13,     8] loss: 2.016 Classification loss:2.014\n",
      "[13,    10] loss: 2.015 Classification loss:2.018\n",
      "[14,     2] loss: 2.016 Classification loss:2.018\n",
      "[14,     4] loss: 2.016 Classification loss:2.013\n",
      "[14,     6] loss: 2.015 Classification loss:2.016\n",
      "[14,     8] loss: 2.010 Classification loss:2.016\n",
      "[14,    10] loss: 2.011 Classification loss:2.012\n",
      "[15,     2] loss: 2.014 Classification loss:2.007\n",
      "[15,     4] loss: 2.012 Classification loss:2.013\n",
      "[15,     6] loss: 2.006 Classification loss:2.010\n",
      "[15,     8] loss: 2.013 Classification loss:2.017\n",
      "[15,    10] loss: 2.005 Classification loss:2.003\n",
      "[16,     2] loss: 2.009 Classification loss:2.002\n",
      "[16,     4] loss: 2.006 Classification loss:2.004\n",
      "[16,     6] loss: 2.009 Classification loss:2.012\n",
      "[16,     8] loss: 2.011 Classification loss:2.010\n",
      "[16,    10] loss: 2.005 Classification loss:2.003\n",
      "[17,     2] loss: 2.002 Classification loss:2.002\n",
      "[17,     4] loss: 2.005 Classification loss:2.003\n",
      "[17,     6] loss: 2.005 Classification loss:2.009\n",
      "[17,     8] loss: 2.002 Classification loss:2.002\n",
      "[17,    10] loss: 2.004 Classification loss:1.998\n",
      "[18,     2] loss: 2.003 Classification loss:2.002\n",
      "[18,     4] loss: 2.004 Classification loss:2.007\n",
      "[18,     6] loss: 2.001 Classification loss:2.000\n",
      "[18,     8] loss: 2.002 Classification loss:2.005\n",
      "[18,    10] loss: 2.001 Classification loss:2.002\n",
      "[19,     2] loss: 2.002 Classification loss:2.000\n",
      "[19,     4] loss: 1.999 Classification loss:2.001\n",
      "[19,     6] loss: 1.998 Classification loss:1.996\n",
      "[19,     8] loss: 1.997 Classification loss:1.995\n",
      "[19,    10] loss: 2.000 Classification loss:2.003\n",
      "[20,     2] loss: 1.999 Classification loss:2.001\n",
      "[20,     4] loss: 1.999 Classification loss:1.997\n",
      "[20,     6] loss: 1.996 Classification loss:1.998\n",
      "[20,     8] loss: 1.999 Classification loss:1.999\n",
      "[20,    10] loss: 1.995 Classification loss:1.997\n",
      "epoch:19\n",
      "Accuracy 10000 test images: 69.21 %\n",
      "[21,     2] loss: 1.997 Classification loss:1.998\n",
      "[21,     4] loss: 1.993 Classification loss:1.991\n",
      "[21,     6] loss: 1.999 Classification loss:1.996\n",
      "[21,     8] loss: 1.995 Classification loss:1.995\n",
      "[21,    10] loss: 1.994 Classification loss:1.992\n",
      "[22,     2] loss: 1.992 Classification loss:1.991\n",
      "[22,     4] loss: 1.996 Classification loss:1.996\n",
      "[22,     6] loss: 1.992 Classification loss:1.997\n",
      "[22,     8] loss: 1.996 Classification loss:2.001\n",
      "[22,    10] loss: 1.994 Classification loss:1.994\n",
      "[23,     2] loss: 1.991 Classification loss:1.990\n",
      "[23,     4] loss: 1.994 Classification loss:1.991\n",
      "[23,     6] loss: 1.992 Classification loss:1.993\n",
      "[23,     8] loss: 1.990 Classification loss:1.989\n",
      "[23,    10] loss: 1.991 Classification loss:1.989\n",
      "[24,     2] loss: 1.990 Classification loss:1.985\n",
      "[24,     4] loss: 1.991 Classification loss:1.987\n",
      "[24,     6] loss: 1.993 Classification loss:1.998\n",
      "[24,     8] loss: 1.992 Classification loss:1.993\n",
      "[24,    10] loss: 1.988 Classification loss:1.984\n",
      "[25,     2] loss: 1.988 Classification loss:1.991\n",
      "[25,     4] loss: 1.989 Classification loss:1.991\n",
      "[25,     6] loss: 1.987 Classification loss:1.985\n",
      "[25,     8] loss: 1.990 Classification loss:1.990\n",
      "[25,    10] loss: 1.990 Classification loss:1.989\n",
      "[26,     2] loss: 1.987 Classification loss:1.985\n",
      "[26,     4] loss: 1.981 Classification loss:1.982\n",
      "[26,     6] loss: 1.988 Classification loss:1.985\n",
      "[26,     8] loss: 1.992 Classification loss:1.994\n",
      "[26,    10] loss: 1.987 Classification loss:1.986\n",
      "[27,     2] loss: 1.987 Classification loss:1.984\n",
      "[27,     4] loss: 1.991 Classification loss:1.990\n",
      "[27,     6] loss: 1.985 Classification loss:1.984\n",
      "[27,     8] loss: 1.983 Classification loss:1.989\n",
      "[27,    10] loss: 1.981 Classification loss:1.982\n",
      "[28,     2] loss: 1.984 Classification loss:1.982\n",
      "[28,     4] loss: 1.985 Classification loss:1.985\n",
      "[28,     6] loss: 1.989 Classification loss:1.990\n",
      "[28,     8] loss: 1.981 Classification loss:1.980\n",
      "[28,    10] loss: 1.986 Classification loss:1.982\n",
      "[29,     2] loss: 1.984 Classification loss:1.983\n",
      "[29,     4] loss: 1.984 Classification loss:1.987\n",
      "[29,     6] loss: 1.979 Classification loss:1.981\n",
      "[29,     8] loss: 1.989 Classification loss:1.985\n",
      "[29,    10] loss: 1.982 Classification loss:1.982\n",
      "[30,     2] loss: 1.981 Classification loss:1.981\n",
      "[30,     4] loss: 1.980 Classification loss:1.981\n",
      "[30,     6] loss: 1.984 Classification loss:1.981\n",
      "[30,     8] loss: 1.986 Classification loss:1.982\n",
      "[30,    10] loss: 1.979 Classification loss:1.971\n",
      "epoch:29\n",
      "Accuracy 10000 test images: 69.74 %\n",
      "[31,     2] loss: 1.983 Classification loss:1.991\n",
      "[31,     4] loss: 1.981 Classification loss:1.978\n",
      "[31,     6] loss: 1.981 Classification loss:1.984\n",
      "[31,     8] loss: 1.984 Classification loss:1.982\n",
      "[31,    10] loss: 1.980 Classification loss:1.985\n",
      "[32,     2] loss: 1.979 Classification loss:1.982\n",
      "[32,     4] loss: 1.981 Classification loss:1.984\n",
      "[32,     6] loss: 1.977 Classification loss:1.979\n",
      "[32,     8] loss: 1.980 Classification loss:1.978\n",
      "[32,    10] loss: 1.981 Classification loss:1.978\n",
      "[33,     2] loss: 1.985 Classification loss:1.980\n",
      "[33,     4] loss: 1.982 Classification loss:1.979\n",
      "[33,     6] loss: 1.977 Classification loss:1.980\n",
      "[33,     8] loss: 1.975 Classification loss:1.974\n",
      "[33,    10] loss: 1.976 Classification loss:1.975\n",
      "[34,     2] loss: 1.973 Classification loss:1.977\n",
      "[34,     4] loss: 1.981 Classification loss:1.984\n",
      "[34,     6] loss: 1.981 Classification loss:1.979\n",
      "[34,     8] loss: 1.979 Classification loss:1.977\n",
      "[34,    10] loss: 1.975 Classification loss:1.975\n",
      "[35,     2] loss: 1.981 Classification loss:1.984\n",
      "[35,     4] loss: 1.977 Classification loss:1.980\n",
      "[35,     6] loss: 1.973 Classification loss:1.971\n",
      "[35,     8] loss: 1.977 Classification loss:1.980\n",
      "[35,    10] loss: 1.975 Classification loss:1.973\n",
      "[36,     2] loss: 1.977 Classification loss:1.979\n",
      "[36,     4] loss: 1.974 Classification loss:1.971\n",
      "[36,     6] loss: 1.979 Classification loss:1.980\n",
      "[36,     8] loss: 1.976 Classification loss:1.975\n",
      "[36,    10] loss: 1.972 Classification loss:1.970\n",
      "[37,     2] loss: 1.978 Classification loss:1.981\n",
      "[37,     4] loss: 1.978 Classification loss:1.976\n",
      "[37,     6] loss: 1.976 Classification loss:1.979\n",
      "[37,     8] loss: 1.976 Classification loss:1.971\n",
      "[37,    10] loss: 1.967 Classification loss:1.968\n",
      "[38,     2] loss: 1.980 Classification loss:1.978\n",
      "[38,     4] loss: 1.977 Classification loss:1.974\n",
      "[38,     6] loss: 1.973 Classification loss:1.970\n",
      "[38,     8] loss: 1.971 Classification loss:1.970\n",
      "[38,    10] loss: 1.973 Classification loss:1.975\n",
      "[39,     2] loss: 1.973 Classification loss:1.976\n",
      "[39,     4] loss: 1.973 Classification loss:1.974\n",
      "[39,     6] loss: 1.969 Classification loss:1.972\n",
      "[39,     8] loss: 1.976 Classification loss:1.976\n",
      "[39,    10] loss: 1.973 Classification loss:1.974\n",
      "[40,     2] loss: 1.969 Classification loss:1.976\n",
      "[40,     4] loss: 1.972 Classification loss:1.970\n",
      "[40,     6] loss: 1.975 Classification loss:1.973\n",
      "[40,     8] loss: 1.971 Classification loss:1.972\n",
      "[40,    10] loss: 1.971 Classification loss:1.973\n",
      "epoch:39\n",
      "Accuracy 10000 test images: 70.17 %\n",
      "Finished Training\n",
      "393.7958312034607\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "9c855411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:20:32.833492Z",
     "start_time": "2025-06-05T09:20:32.824446Z"
    }
   },
   "source": [
    "PATH = './Training Results/02-PAT.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "PATH = ''"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "6a15f924",
   "metadata": {},
   "source": [
    "### 03-SAT-In silico"
   ]
  },
  {
   "cell_type": "code",
   "id": "158127be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:20:32.863173Z",
     "start_time": "2025-06-05T09:20:32.833492Z"
    }
   },
   "source": [
    "from sam import SAM\n",
    "import torch.optim as optim\n",
    "net = LeNet5()\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "base_optimizer = torch.optim.Adam\n",
    "optimizer = SAM(net.parameters(), rho=0.3, base_optimizer=base_optimizer,lr=1e-1)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 400, gamma = 0.5)"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "6cd63720",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:29:06.689833Z",
     "start_time": "2025-06-05T09:20:32.864243Z"
    }
   },
   "source": [
    "import time\n",
    "net.to(device)\n",
    "start = time.time()\n",
    "for epoch in range(40):  # loop over the dataset multiple times\n",
    "### You can consider increasing the training epochs if the accuracy does not converge\n",
    "### I find the different initialization results may lead to different training epochs, sometimes short, sometimes long\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # forward + backward + optimize\n",
    "        outputs_sim = net(inputs)\n",
    "        loss0 = criterion(outputs_sim, labels)\n",
    "\n",
    "        loss = loss0\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "        \n",
    "        \n",
    "        outputs_sim_SAM = net(inputs)\n",
    "        lossSAM0 = criterion(outputs_sim_SAM, labels)\n",
    "\n",
    "        lossSAM = lossSAM0\n",
    "        lossSAM.backward()\n",
    "        optimizer.second_step(zero_grad=True) \n",
    "        # net.apply_constraints()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2 == 1:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    scheduler.step()\n",
    "    if epoch % 10 == 9:    # print every 2000 mini-batches\n",
    "        print(f'epoch:{epoch}')\n",
    "        net.to(device)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                # calculate outputs by running images through the network\n",
    "                net.layer1.theta.data = net.layer1.theta.data + b0_theta_error\n",
    "                net.layer1.phi.data = net.layer1.phi.data + b0_phi_error\n",
    "                net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                        torch.as_tensor(nenn_n, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepn_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nenp_n, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepp_n, dtype=torch.float32).cuda()                    \n",
    "                outputs = net.phy_forward(inputs)\n",
    "                net.layer1.theta.data = net.layer1.theta.data - b0_theta_error\n",
    "                net.layer1.phi.data = net.layer1.phi.data - b0_phi_error \n",
    "                net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                        torch.as_tensor(nenn_init, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepn_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nenp_init, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepp_init, dtype=torch.float32).cuda() \n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print(f'Accuracy 10000 test images: {100 * correct / total} %')\n",
    "print('Finished Training')\n",
    "end = time.time()\n",
    "print(end-start)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     2] loss: 2.313\n",
      "[1,     4] loss: 2.306\n",
      "[1,     6] loss: 2.289\n",
      "[1,     8] loss: 2.241\n",
      "[1,    10] loss: 2.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\GPU_Pytorchpy39\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,     2] loss: 2.103\n",
      "[2,     4] loss: 2.055\n",
      "[2,     6] loss: 1.954\n",
      "[2,     8] loss: 1.898\n",
      "[2,    10] loss: 1.841\n",
      "[3,     2] loss: 1.800\n",
      "[3,     4] loss: 1.770\n",
      "[3,     6] loss: 1.755\n",
      "[3,     8] loss: 1.728\n",
      "[3,    10] loss: 1.719\n",
      "[4,     2] loss: 1.702\n",
      "[4,     4] loss: 1.694\n",
      "[4,     6] loss: 1.679\n",
      "[4,     8] loss: 1.668\n",
      "[4,    10] loss: 1.655\n",
      "[5,     2] loss: 1.639\n",
      "[5,     4] loss: 1.631\n",
      "[5,     6] loss: 1.616\n",
      "[5,     8] loss: 1.612\n",
      "[5,    10] loss: 1.597\n",
      "[6,     2] loss: 1.592\n",
      "[6,     4] loss: 1.583\n",
      "[6,     6] loss: 1.578\n",
      "[6,     8] loss: 1.574\n",
      "[6,    10] loss: 1.574\n",
      "[7,     2] loss: 1.566\n",
      "[7,     4] loss: 1.558\n",
      "[7,     6] loss: 1.557\n",
      "[7,     8] loss: 1.553\n",
      "[7,    10] loss: 1.549\n",
      "[8,     2] loss: 1.546\n",
      "[8,     4] loss: 1.544\n",
      "[8,     6] loss: 1.541\n",
      "[8,     8] loss: 1.541\n",
      "[8,    10] loss: 1.538\n",
      "[9,     2] loss: 1.538\n",
      "[9,     4] loss: 1.537\n",
      "[9,     6] loss: 1.533\n",
      "[9,     8] loss: 1.532\n",
      "[9,    10] loss: 1.527\n",
      "[10,     2] loss: 1.530\n",
      "[10,     4] loss: 1.525\n",
      "[10,     6] loss: 1.525\n",
      "[10,     8] loss: 1.525\n",
      "[10,    10] loss: 1.523\n",
      "epoch:9\n",
      "Accuracy 10000 test images: 69.75 %\n",
      "[11,     2] loss: 1.523\n",
      "[11,     4] loss: 1.520\n",
      "[11,     6] loss: 1.520\n",
      "[11,     8] loss: 1.518\n",
      "[11,    10] loss: 1.519\n",
      "[12,     2] loss: 1.518\n",
      "[12,     4] loss: 1.515\n",
      "[12,     6] loss: 1.515\n",
      "[12,     8] loss: 1.515\n",
      "[12,    10] loss: 1.515\n",
      "[13,     2] loss: 1.513\n",
      "[13,     4] loss: 1.513\n",
      "[13,     6] loss: 1.512\n",
      "[13,     8] loss: 1.513\n",
      "[13,    10] loss: 1.512\n",
      "[14,     2] loss: 1.508\n",
      "[14,     4] loss: 1.512\n",
      "[14,     6] loss: 1.511\n",
      "[14,     8] loss: 1.510\n",
      "[14,    10] loss: 1.509\n",
      "[15,     2] loss: 1.508\n",
      "[15,     4] loss: 1.508\n",
      "[15,     6] loss: 1.507\n",
      "[15,     8] loss: 1.508\n",
      "[15,    10] loss: 1.508\n",
      "[16,     2] loss: 1.508\n",
      "[16,     4] loss: 1.505\n",
      "[16,     6] loss: 1.505\n",
      "[16,     8] loss: 1.507\n",
      "[16,    10] loss: 1.505\n",
      "[17,     2] loss: 1.505\n",
      "[17,     4] loss: 1.504\n",
      "[17,     6] loss: 1.506\n",
      "[17,     8] loss: 1.503\n",
      "[17,    10] loss: 1.505\n",
      "[18,     2] loss: 1.503\n",
      "[18,     4] loss: 1.504\n",
      "[18,     6] loss: 1.503\n",
      "[18,     8] loss: 1.503\n",
      "[18,    10] loss: 1.503\n",
      "[19,     2] loss: 1.504\n",
      "[19,     4] loss: 1.502\n",
      "[19,     6] loss: 1.501\n",
      "[19,     8] loss: 1.501\n",
      "[19,    10] loss: 1.502\n",
      "[20,     2] loss: 1.501\n",
      "[20,     4] loss: 1.501\n",
      "[20,     6] loss: 1.501\n",
      "[20,     8] loss: 1.501\n",
      "[20,    10] loss: 1.500\n",
      "epoch:19\n",
      "Accuracy 10000 test images: 72.64 %\n",
      "[21,     2] loss: 1.501\n",
      "[21,     4] loss: 1.500\n",
      "[21,     6] loss: 1.500\n",
      "[21,     8] loss: 1.500\n",
      "[21,    10] loss: 1.500\n",
      "[22,     2] loss: 1.500\n",
      "[22,     4] loss: 1.500\n",
      "[22,     6] loss: 1.499\n",
      "[22,     8] loss: 1.498\n",
      "[22,    10] loss: 1.499\n",
      "[23,     2] loss: 1.499\n",
      "[23,     4] loss: 1.498\n",
      "[23,     6] loss: 1.501\n",
      "[23,     8] loss: 1.498\n",
      "[23,    10] loss: 1.498\n",
      "[24,     2] loss: 1.497\n",
      "[24,     4] loss: 1.499\n",
      "[24,     6] loss: 1.499\n",
      "[24,     8] loss: 1.498\n",
      "[24,    10] loss: 1.498\n",
      "[25,     2] loss: 1.499\n",
      "[25,     4] loss: 1.499\n",
      "[25,     6] loss: 1.497\n",
      "[25,     8] loss: 1.497\n",
      "[25,    10] loss: 1.497\n",
      "[26,     2] loss: 1.497\n",
      "[26,     4] loss: 1.497\n",
      "[26,     6] loss: 1.496\n",
      "[26,     8] loss: 1.499\n",
      "[26,    10] loss: 1.497\n",
      "[27,     2] loss: 1.496\n",
      "[27,     4] loss: 1.497\n",
      "[27,     6] loss: 1.498\n",
      "[27,     8] loss: 1.495\n",
      "[27,    10] loss: 1.497\n",
      "[28,     2] loss: 1.497\n",
      "[28,     4] loss: 1.495\n",
      "[28,     6] loss: 1.498\n",
      "[28,     8] loss: 1.495\n",
      "[28,    10] loss: 1.495\n",
      "[29,     2] loss: 1.498\n",
      "[29,     4] loss: 1.512\n",
      "[29,     6] loss: 1.515\n",
      "[29,     8] loss: 1.513\n",
      "[29,    10] loss: 1.511\n",
      "[30,     2] loss: 1.507\n",
      "[30,     4] loss: 1.508\n",
      "[30,     6] loss: 1.503\n",
      "[30,     8] loss: 1.505\n",
      "[30,    10] loss: 1.504\n",
      "epoch:29\n",
      "Accuracy 10000 test images: 82.59 %\n",
      "[31,     2] loss: 1.501\n",
      "[31,     4] loss: 1.501\n",
      "[31,     6] loss: 1.501\n",
      "[31,     8] loss: 1.500\n",
      "[31,    10] loss: 1.497\n",
      "[32,     2] loss: 1.497\n",
      "[32,     4] loss: 1.496\n",
      "[32,     6] loss: 1.498\n",
      "[32,     8] loss: 1.497\n",
      "[32,    10] loss: 1.497\n",
      "[33,     2] loss: 1.495\n",
      "[33,     4] loss: 1.495\n",
      "[33,     6] loss: 1.497\n",
      "[33,     8] loss: 1.495\n",
      "[33,    10] loss: 1.495\n",
      "[34,     2] loss: 1.495\n",
      "[34,     4] loss: 1.495\n",
      "[34,     6] loss: 1.496\n",
      "[34,     8] loss: 1.494\n",
      "[34,    10] loss: 1.494\n",
      "[35,     2] loss: 1.493\n",
      "[35,     4] loss: 1.494\n",
      "[35,     6] loss: 1.494\n",
      "[35,     8] loss: 1.494\n",
      "[35,    10] loss: 1.495\n",
      "[36,     2] loss: 1.493\n",
      "[36,     4] loss: 1.496\n",
      "[36,     6] loss: 1.492\n",
      "[36,     8] loss: 1.494\n",
      "[36,    10] loss: 1.494\n",
      "[37,     2] loss: 1.494\n",
      "[37,     4] loss: 1.494\n",
      "[37,     6] loss: 1.493\n",
      "[37,     8] loss: 1.494\n",
      "[37,    10] loss: 1.494\n",
      "[38,     2] loss: 1.493\n",
      "[38,     4] loss: 1.494\n",
      "[38,     6] loss: 1.494\n",
      "[38,     8] loss: 1.494\n",
      "[38,    10] loss: 1.494\n",
      "[39,     2] loss: 1.494\n",
      "[39,     4] loss: 1.492\n",
      "[39,     6] loss: 1.494\n",
      "[39,     8] loss: 1.493\n",
      "[39,    10] loss: 1.493\n",
      "[40,     2] loss: 1.493\n",
      "[40,     4] loss: 1.492\n",
      "[40,     6] loss: 1.493\n",
      "[40,     8] loss: 1.493\n",
      "[40,    10] loss: 1.493\n",
      "epoch:39\n",
      "Accuracy 10000 test images: 92.31 %\n",
      "Finished Training\n",
      "513.8091685771942\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "2c841a72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:29:06.700048Z",
     "start_time": "2025-06-05T09:29:06.689833Z"
    }
   },
   "source": [
    "PATH = './Training Results/03-SAT-In silico.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "PATH = ''"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "d17d5d43",
   "metadata": {},
   "source": [
    "### 04-SAT-In situ"
   ]
  },
  {
   "cell_type": "code",
   "id": "857102ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:29:06.721035Z",
     "start_time": "2025-06-05T09:29:06.700048Z"
    }
   },
   "source": [
    "from sam import SAM\n",
    "import torch.optim as optim\n",
    "net = LeNet5()\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "base_optimizer = torch.optim.Adam\n",
    "optimizer = SAM(net.parameters(), rho=0.3, base_optimizer=base_optimizer,lr=1e-1)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 400, gamma = 0.5)"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "9736298b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:39:29.796190Z",
     "start_time": "2025-06-05T09:29:06.721035Z"
    }
   },
   "source": [
    "import time\n",
    "net.to(device)\n",
    "start = time.time()\n",
    "for epoch in range(40):  # loop over the dataset multiple times\n",
    "### You can consider increasing the training epochs if the accuracy does not converge\n",
    "### I find the different initialization results may lead to different training epochs, sometimes short, sometimes long\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # forward + backward + optimize\n",
    "        outputs_sim = net(inputs)\n",
    "        with torch.no_grad():\n",
    "            net.layer1.theta.data = net.layer1.theta.data + b0_theta_error\n",
    "            net.layer1.phi.data = net.layer1.phi.data + b0_phi_error\n",
    "            net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                    torch.as_tensor(nenn_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepn_n, dtype=torch.float32).cuda(), \\\n",
    "                    torch.as_tensor(nenp_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepp_n, dtype=torch.float32).cuda()\n",
    "            outputs_phy = net.phy_forward(inputs)\n",
    "            net.phy_replace_sim()\n",
    "            outputs_sim.data.copy_(outputs_phy.data)\n",
    "            net.layer1.theta.data = net.layer1.theta.data - b0_theta_error\n",
    "            net.layer1.phi.data = net.layer1.phi.data - b0_phi_error \n",
    "            net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                    torch.as_tensor(nenn_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepn_init, dtype=torch.float32).cuda(), \\\n",
    "                    torch.as_tensor(nenp_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepp_init, dtype=torch.float32).cuda()   \n",
    "        loss0 = criterion(outputs_sim, labels)\n",
    "\n",
    "        loss = loss0\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "        \n",
    "        \n",
    "        outputs_sim_SAM = net(inputs)\n",
    "        with torch.no_grad():\n",
    "            net.layer1.theta.data = net.layer1.theta.data + b0_theta_error\n",
    "            net.layer1.phi.data = net.layer1.phi.data + b0_phi_error\n",
    "            net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                    torch.as_tensor(nenn_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepn_n, dtype=torch.float32).cuda(), \\\n",
    "                    torch.as_tensor(nenp_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepp_n, dtype=torch.float32).cuda()  \n",
    "            outputs_phy_SAM = net.phy_forward(inputs)\n",
    "            net.phy_replace_sim()\n",
    "            outputs_sim_SAM.data.copy_(outputs_phy_SAM.data)\n",
    "            net.layer1.theta.data = net.layer1.theta.data - b0_theta_error\n",
    "            net.layer1.phi.data = net.layer1.phi.data - b0_phi_error  \n",
    "            net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                    torch.as_tensor(nenn_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepn_init, dtype=torch.float32).cuda(), \\\n",
    "                    torch.as_tensor(nenp_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepp_init, dtype=torch.float32).cuda()  \n",
    "        lossSAM0 = criterion(outputs_sim_SAM, labels)\n",
    "\n",
    "        lossSAM = lossSAM0\n",
    "        lossSAM.backward()\n",
    "        optimizer.second_step(zero_grad=True) \n",
    "        # net.apply_constraints()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2 == 1:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    scheduler.step()\n",
    "    if epoch % 10 == 9:    # print every 2000 mini-batches\n",
    "        print(f'epoch:{epoch}')\n",
    "        net.to(device)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                # calculate outputs by running images through the network\n",
    "                net.layer1.theta.data = net.layer1.theta.data + b0_theta_error\n",
    "                net.layer1.phi.data = net.layer1.phi.data + b0_phi_error\n",
    "                net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                        torch.as_tensor(nenn_n, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepn_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nenp_n, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepp_n, dtype=torch.float32).cuda()                    \n",
    "                outputs = net.phy_forward(inputs)\n",
    "                net.layer1.theta.data = net.layer1.theta.data - b0_theta_error\n",
    "                net.layer1.phi.data = net.layer1.phi.data - b0_phi_error \n",
    "                net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                        torch.as_tensor(nenn_init, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepn_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nenp_init, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepp_init, dtype=torch.float32).cuda() \n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print(f'Accuracy 10000 test images: {100 * correct / total} %')\n",
    "print('Finished Training')\n",
    "end = time.time()\n",
    "print(end-start)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     2] loss: 2.314\n",
      "[1,     4] loss: 2.307\n",
      "[1,     6] loss: 2.294\n",
      "[1,     8] loss: 2.291\n",
      "[1,    10] loss: 2.268\n",
      "[2,     2] loss: 2.264\n",
      "[2,     4] loss: 2.238\n",
      "[2,     6] loss: 2.195\n",
      "[2,     8] loss: 2.166\n",
      "[2,    10] loss: 2.191\n",
      "[3,     2] loss: 2.193\n",
      "[3,     4] loss: 2.215\n",
      "[3,     6] loss: 2.150\n",
      "[3,     8] loss: 2.155\n",
      "[3,    10] loss: 2.141\n",
      "[4,     2] loss: 2.137\n",
      "[4,     4] loss: 2.133\n",
      "[4,     6] loss: 2.115\n",
      "[4,     8] loss: 2.152\n",
      "[4,    10] loss: 2.124\n",
      "[5,     2] loss: 2.087\n",
      "[5,     4] loss: 2.071\n",
      "[5,     6] loss: 2.064\n",
      "[5,     8] loss: 2.057\n",
      "[5,    10] loss: 2.061\n",
      "[6,     2] loss: 2.057\n",
      "[6,     4] loss: 2.029\n",
      "[6,     6] loss: 2.035\n",
      "[6,     8] loss: 2.027\n",
      "[6,    10] loss: 2.034\n",
      "[7,     2] loss: 2.036\n",
      "[7,     4] loss: 2.034\n",
      "[7,     6] loss: 2.032\n",
      "[7,     8] loss: 2.028\n",
      "[7,    10] loss: 2.017\n",
      "[8,     2] loss: 2.007\n",
      "[8,     4] loss: 1.986\n",
      "[8,     6] loss: 1.987\n",
      "[8,     8] loss: 1.994\n",
      "[8,    10] loss: 1.993\n",
      "[9,     2] loss: 1.969\n",
      "[9,     4] loss: 1.968\n",
      "[9,     6] loss: 1.992\n",
      "[9,     8] loss: 1.962\n",
      "[9,    10] loss: 1.968\n",
      "[10,     2] loss: 1.976\n",
      "[10,     4] loss: 1.968\n",
      "[10,     6] loss: 1.953\n",
      "[10,     8] loss: 1.960\n",
      "[10,    10] loss: 1.949\n",
      "epoch:9\n",
      "Accuracy 10000 test images: 77.65 %\n",
      "[11,     2] loss: 1.952\n",
      "[11,     4] loss: 1.948\n",
      "[11,     6] loss: 1.954\n",
      "[11,     8] loss: 1.934\n",
      "[11,    10] loss: 1.926\n",
      "[12,     2] loss: 1.940\n",
      "[12,     4] loss: 1.930\n",
      "[12,     6] loss: 1.924\n",
      "[12,     8] loss: 1.924\n",
      "[12,    10] loss: 1.940\n",
      "[13,     2] loss: 1.932\n",
      "[13,     4] loss: 1.940\n",
      "[13,     6] loss: 1.924\n",
      "[13,     8] loss: 1.927\n",
      "[13,    10] loss: 1.936\n",
      "[14,     2] loss: 1.935\n",
      "[14,     4] loss: 1.940\n",
      "[14,     6] loss: 1.909\n",
      "[14,     8] loss: 1.916\n",
      "[14,    10] loss: 1.935\n",
      "[15,     2] loss: 1.921\n",
      "[15,     4] loss: 1.918\n",
      "[15,     6] loss: 1.921\n",
      "[15,     8] loss: 1.910\n",
      "[15,    10] loss: 1.919\n",
      "[16,     2] loss: 1.922\n",
      "[16,     4] loss: 1.915\n",
      "[16,     6] loss: 1.915\n",
      "[16,     8] loss: 1.911\n",
      "[16,    10] loss: 1.909\n",
      "[17,     2] loss: 1.896\n",
      "[17,     4] loss: 1.902\n",
      "[17,     6] loss: 1.906\n",
      "[17,     8] loss: 1.905\n",
      "[17,    10] loss: 1.901\n",
      "[18,     2] loss: 1.903\n",
      "[18,     4] loss: 1.897\n",
      "[18,     6] loss: 1.893\n",
      "[18,     8] loss: 1.886\n",
      "[18,    10] loss: 1.894\n",
      "[19,     2] loss: 1.886\n",
      "[19,     4] loss: 1.879\n",
      "[19,     6] loss: 1.879\n",
      "[19,     8] loss: 1.879\n",
      "[19,    10] loss: 1.869\n",
      "[20,     2] loss: 1.877\n",
      "[20,     4] loss: 1.881\n",
      "[20,     6] loss: 1.865\n",
      "[20,     8] loss: 1.868\n",
      "[20,    10] loss: 1.872\n",
      "epoch:19\n",
      "Accuracy 10000 test images: 88.52 %\n",
      "[21,     2] loss: 1.854\n",
      "[21,     4] loss: 1.868\n",
      "[21,     6] loss: 1.875\n",
      "[21,     8] loss: 1.869\n",
      "[21,    10] loss: 1.873\n",
      "[22,     2] loss: 1.869\n",
      "[22,     4] loss: 1.865\n",
      "[22,     6] loss: 1.875\n",
      "[22,     8] loss: 1.870\n",
      "[22,    10] loss: 1.860\n",
      "[23,     2] loss: 1.846\n",
      "[23,     4] loss: 1.852\n",
      "[23,     6] loss: 1.874\n",
      "[23,     8] loss: 1.863\n",
      "[23,    10] loss: 1.846\n",
      "[24,     2] loss: 1.852\n",
      "[24,     4] loss: 1.853\n",
      "[24,     6] loss: 1.848\n",
      "[24,     8] loss: 1.842\n",
      "[24,    10] loss: 1.847\n",
      "[25,     2] loss: 1.844\n",
      "[25,     4] loss: 1.843\n",
      "[25,     6] loss: 1.834\n",
      "[25,     8] loss: 1.842\n",
      "[25,    10] loss: 1.832\n",
      "[26,     2] loss: 1.826\n",
      "[26,     4] loss: 1.819\n",
      "[26,     6] loss: 1.838\n",
      "[26,     8] loss: 1.831\n",
      "[26,    10] loss: 1.829\n",
      "[27,     2] loss: 1.827\n",
      "[27,     4] loss: 1.831\n",
      "[27,     6] loss: 1.829\n",
      "[27,     8] loss: 1.818\n",
      "[27,    10] loss: 1.826\n",
      "[28,     2] loss: 1.823\n",
      "[28,     4] loss: 1.811\n",
      "[28,     6] loss: 1.807\n",
      "[28,     8] loss: 1.814\n",
      "[28,    10] loss: 1.794\n",
      "[29,     2] loss: 1.802\n",
      "[29,     4] loss: 1.807\n",
      "[29,     6] loss: 1.788\n",
      "[29,     8] loss: 1.791\n",
      "[29,    10] loss: 1.801\n",
      "[30,     2] loss: 1.796\n",
      "[30,     4] loss: 1.805\n",
      "[30,     6] loss: 1.797\n",
      "[30,     8] loss: 1.813\n",
      "[30,    10] loss: 1.808\n",
      "epoch:29\n",
      "Accuracy 10000 test images: 94.56 %\n",
      "[31,     2] loss: 1.815\n",
      "[31,     4] loss: 1.819\n",
      "[31,     6] loss: 1.809\n",
      "[31,     8] loss: 1.808\n",
      "[31,    10] loss: 1.801\n",
      "[32,     2] loss: 1.796\n",
      "[32,     4] loss: 1.797\n",
      "[32,     6] loss: 1.787\n",
      "[32,     8] loss: 1.795\n",
      "[32,    10] loss: 1.786\n",
      "[33,     2] loss: 1.789\n",
      "[33,     4] loss: 1.785\n",
      "[33,     6] loss: 1.799\n",
      "[33,     8] loss: 1.793\n",
      "[33,    10] loss: 1.785\n",
      "[34,     2] loss: 1.787\n",
      "[34,     4] loss: 1.797\n",
      "[34,     6] loss: 1.806\n",
      "[34,     8] loss: 1.796\n",
      "[34,    10] loss: 1.777\n",
      "[35,     2] loss: 1.786\n",
      "[35,     4] loss: 1.794\n",
      "[35,     6] loss: 1.788\n",
      "[35,     8] loss: 1.779\n",
      "[35,    10] loss: 1.771\n",
      "[36,     2] loss: 1.776\n",
      "[36,     4] loss: 1.788\n",
      "[36,     6] loss: 1.781\n",
      "[36,     8] loss: 1.764\n",
      "[36,    10] loss: 1.780\n",
      "[37,     2] loss: 1.778\n",
      "[37,     4] loss: 1.781\n",
      "[37,     6] loss: 1.773\n",
      "[37,     8] loss: 1.769\n",
      "[37,    10] loss: 1.771\n",
      "[38,     2] loss: 1.764\n",
      "[38,     4] loss: 1.771\n",
      "[38,     6] loss: 1.763\n",
      "[38,     8] loss: 1.762\n",
      "[38,    10] loss: 1.756\n",
      "[39,     2] loss: 1.751\n",
      "[39,     4] loss: 1.749\n",
      "[39,     6] loss: 1.749\n",
      "[39,     8] loss: 1.732\n",
      "[39,    10] loss: 1.739\n",
      "[40,     2] loss: 1.748\n",
      "[40,     4] loss: 1.742\n",
      "[40,     6] loss: 1.746\n",
      "[40,     8] loss: 1.747\n",
      "[40,    10] loss: 1.737\n",
      "epoch:39\n",
      "Accuracy 10000 test images: 97.05 %\n",
      "Finished Training\n",
      "623.0538592338562\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "8bf3af65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:39:29.806592Z",
     "start_time": "2025-06-05T09:39:29.796190Z"
    }
   },
   "source": [
    "PATH = './Training Results/04-SAT-In situ.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "PATH = ''"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "e0723bd7",
   "metadata": {},
   "source": [
    "### 05-DAT (Requires redefining the model)"
   ]
  },
  {
   "cell_type": "code",
   "id": "5deb789f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:39:29.887439Z",
     "start_time": "2025-06-05T09:39:29.806592Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import net\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 64)\n",
    "        self.norm1 = nn.BatchNorm2d(6)\n",
    "        self.norm2 = nn.BatchNorm2d(16)\n",
    "        self.norm3 = nn.BatchNorm1d(120)\n",
    "        self.layer1 = RMTorch(64, phase_error = 0, phase_error_files = None,bs_error=0,bs_error_files = None)\n",
    "        self.output = CNormSq()\n",
    "        self.cn1 = net.ComplexUNet(size = [8,8],kernel_size = 3, bn_flag=True, CB_layers = [3,3,3], FM_num = [4,8,16])\n",
    "        self.cn2 = net.ComplexUNet(size = [8,8],kernel_size = 3, bn_flag=True, CB_layers = [3,3,3], FM_num = [4,8,16])\n",
    "        self.cn3 = net.ComplexUNet(size = [8,8],kernel_size = 3, bn_flag=True, CB_layers = [3,3,3], FM_num = [4,8,16])\n",
    "        self.cn4 = net.ComplexUNet(size = [8,8],kernel_size = 3, bn_flag=True, CB_layers = [3,3,3], FM_num = [4,8,16])\n",
    "        self.cn5 = net.ComplexUNet(size = [8,8],kernel_size = 3, bn_flag=True, CB_layers = [3,3,3], FM_num = [4,8,16])\n",
    "        self.cn6 = net.ComplexUNet(size = [8,8],kernel_size = 3, bn_flag=True, CB_layers = [3,3,3], FM_num = [4,8,16])        \n",
    "    \n",
    "    def forward(self,x,cn_weight=1.0):\n",
    "\n",
    "        x = F.max_pool2d(F.relu(self.norm1(self.conv1(x))), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.norm2(self.conv2(x))), (2, 2))\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.fc1(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.stack((x, torch.zeros(x.shape, dtype=torch.float32, device=x.device)), dim=0)\n",
    "        x,_,_,_ = self.layer1(x)\n",
    "        x = (self.cn1(x) + self.cn2(x) + self.cn3(x) + self.cn4(x) + self.cn5(x) + self.cn6(x)) * cn_weight + x\n",
    "        self.at_sensor = x\n",
    "        x = self.output(x)\n",
    "        self.at_sensor_intensity = x\n",
    "        return self.at_sensor_intensity[:,:10]\n",
    "    \n",
    "    def phy_forward(self,x):\n",
    "        self.in_outs_phy = []\n",
    "        with torch.no_grad():\n",
    "            x = F.max_pool2d(F.relu(self.norm1(self.conv1(x))), (2, 2))\n",
    "            x = F.max_pool2d(F.relu(self.norm2(self.conv2(x))), (2, 2))\n",
    "            x = x.view(x.size(0), -1) \n",
    "            x = self.fc1(x)\n",
    "            x = self.norm3(x)\n",
    "            x = self.fc2(x)\n",
    "            x = torch.stack((x, torch.zeros(x.shape, dtype=torch.float32, device=x.device)), dim=0)\n",
    "            x, _, _, _ = self.layer1(x)\n",
    "            self.at_sensor_phy = x\n",
    "            x = self.output(x)\n",
    "            self.at_sensor_intensity_phy = x\n",
    "        return self.at_sensor_intensity_phy[:,:10]     \n",
    "    \n",
    "    def phy_replace_sim(self):\n",
    "        with torch.no_grad():\n",
    "            angle = torch.angle(torch.complex(self.at_sensor[0, :, :], self.at_sensor[1, :, :]))\n",
    "            amp = torch.abs(torch.complex(self.at_sensor_phy[0, :, :], self.at_sensor_phy[1, :, :]))\n",
    "            new_data = amp * torch.exp(1j * angle)\n",
    "            data_transfer = torch.stack([torch.real(new_data), torch.imag(new_data)], dim=0)\n",
    "            self.at_sensor.data.copy_(data_transfer.data)\n",
    "            self.at_sensor_intensity.data.copy_(self.at_sensor_intensity_phy.data)             \n",
    "\n",
    "    def apply_constraints(self):\n",
    "        self.conv1.cuda().weight.data = torch.clamp(self.conv1.cuda().weight.data, -1, 1)\n",
    "        self.conv2.cuda().weight.data = torch.clamp(self.conv2.cuda().weight.data, -1, 1)\n",
    "        self.fc1.cuda().weight.data = torch.clamp(self.fc1.cuda().weight.data, -1, 1)\n",
    "        self.fc2.cuda().weight.data = torch.clamp(self.fc2.cuda().weight.data, -1, 1)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "net = LeNet5()\n",
    "net.to(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=64, bias=True)\n",
       "  (norm1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm3): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): RMTorch()\n",
       "  (output): CNormSq()\n",
       "  (cn1): ComplexUNet(\n",
       "    (ConvB1): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (ConvB2): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (ConvB3): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (DownConv1): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv_i): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (DownConv2): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv_i): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (UpConv1): ComplexConvLayer(\n",
       "      (ComplexConvT2d): ComplexConvTranspose2d(\n",
       "        (conv_tran_r): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (conv_tran_i): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (UpConv2): ComplexConvLayer(\n",
       "      (ComplexConvT2d): ComplexConvTranspose2d(\n",
       "        (conv_tran_r): ConvTranspose2d(16, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (conv_tran_i): ConvTranspose2d(16, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (OutConv): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_i): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cn2): ComplexUNet(\n",
       "    (ConvB1): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (ConvB2): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (ConvB3): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (DownConv1): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv_i): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (DownConv2): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv_i): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (UpConv1): ComplexConvLayer(\n",
       "      (ComplexConvT2d): ComplexConvTranspose2d(\n",
       "        (conv_tran_r): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (conv_tran_i): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (UpConv2): ComplexConvLayer(\n",
       "      (ComplexConvT2d): ComplexConvTranspose2d(\n",
       "        (conv_tran_r): ConvTranspose2d(16, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (conv_tran_i): ConvTranspose2d(16, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (OutConv): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_i): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cn3): ComplexUNet(\n",
       "    (ConvB1): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (ConvB2): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (ConvB3): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (DownConv1): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv_i): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (DownConv2): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv_i): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (UpConv1): ComplexConvLayer(\n",
       "      (ComplexConvT2d): ComplexConvTranspose2d(\n",
       "        (conv_tran_r): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (conv_tran_i): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (UpConv2): ComplexConvLayer(\n",
       "      (ComplexConvT2d): ComplexConvTranspose2d(\n",
       "        (conv_tran_r): ConvTranspose2d(16, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (conv_tran_i): ConvTranspose2d(16, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (OutConv): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_i): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cn4): ComplexUNet(\n",
       "    (ConvB1): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (ConvB2): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (ConvB3): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (DownConv1): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv_i): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (DownConv2): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv_i): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (UpConv1): ComplexConvLayer(\n",
       "      (ComplexConvT2d): ComplexConvTranspose2d(\n",
       "        (conv_tran_r): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (conv_tran_i): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (UpConv2): ComplexConvLayer(\n",
       "      (ComplexConvT2d): ComplexConvTranspose2d(\n",
       "        (conv_tran_r): ConvTranspose2d(16, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (conv_tran_i): ConvTranspose2d(16, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (OutConv): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_i): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cn5): ComplexUNet(\n",
       "    (ConvB1): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (ConvB2): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (ConvB3): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (DownConv1): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv_i): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (DownConv2): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv_i): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (UpConv1): ComplexConvLayer(\n",
       "      (ComplexConvT2d): ComplexConvTranspose2d(\n",
       "        (conv_tran_r): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (conv_tran_i): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (UpConv2): ComplexConvLayer(\n",
       "      (ComplexConvT2d): ComplexConvTranspose2d(\n",
       "        (conv_tran_r): ConvTranspose2d(16, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (conv_tran_i): ConvTranspose2d(16, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (OutConv): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_i): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cn6): ComplexUNet(\n",
       "    (ConvB1): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (ConvB2): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (ConvB3): ComplexConvBlock(\n",
       "      (ComplexConv-0): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-1): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "      (ComplexConv-2): ComplexConvLayer(\n",
       "        (ComplexConv2d): ComplexConv2d(\n",
       "          (conv_r): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_i): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (ComplexBN): ComplexBatchNorm2d()\n",
       "        (ComplexAct): ComplexReLU()\n",
       "      )\n",
       "    )\n",
       "    (DownConv1): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv_i): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (DownConv2): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv_i): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (UpConv1): ComplexConvLayer(\n",
       "      (ComplexConvT2d): ComplexConvTranspose2d(\n",
       "        (conv_tran_r): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (conv_tran_i): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (UpConv2): ComplexConvLayer(\n",
       "      (ComplexConvT2d): ComplexConvTranspose2d(\n",
       "        (conv_tran_r): ConvTranspose2d(16, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (conv_tran_i): ConvTranspose2d(16, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      )\n",
       "      (ComplexBN): ComplexBatchNorm2d()\n",
       "      (ComplexAct): ComplexReLU()\n",
       "    )\n",
       "    (OutConv): ComplexConvLayer(\n",
       "      (ComplexConv2d): ComplexConv2d(\n",
       "        (conv_r): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_i): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "d58a60e705e784b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:39:29.897801Z",
     "start_time": "2025-06-05T09:39:29.887439Z"
    }
   },
   "source": [
    "[nenn, nepn, nenp, nepp], [enn, epn, enp, epp] = net.layer1.mesh_model.mzi_error_tensors()\n",
    "[nenn_init, nepn_init, nenp_init, nepp_init] = [nenn, nepn, nenp, nepp]"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "45940413",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:39:29.908253Z",
     "start_time": "2025-06-05T09:39:29.897801Z"
    }
   },
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "params = list(net.parameters())\n",
    "cn1_params = list(net.cn1.parameters())\n",
    "params_to_optimize = [p for p in params if id(p) not in [id(cn1_p) for cn1_p in cn1_params]]\n",
    "optimizer = optim.SGD(params_to_optimize, lr=0.1, momentum=0.5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 30, gamma = 0.5)\n",
    "criterion_cn = nn.MSELoss()\n",
    "params = list(net.cn1.parameters()) + list(net.cn2.parameters()) + list(net.cn3.parameters()) + list(net.cn4.parameters()) + list(net.cn5.parameters()) + list(net.cn6.parameters())\n",
    "optimizer_cn = optim.Adam(params, lr=0.001)\n",
    "scheduler_cn = optim.lr_scheduler.StepLR(optimizer_cn, step_size = 60, gamma = 0.5)"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "3ef9f19df8bebc5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T10:00:42.666961Z",
     "start_time": "2025-06-05T09:39:29.908253Z"
    }
   },
   "source": [
    "import time\n",
    "net.to(device)\n",
    "start = time.time()\n",
    "for epoch in range(60):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    running_loss_cn = 0.0\n",
    "    cn_weight = 0. if epoch < 20 else 1. \n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        if epoch < 20:\n",
    "            optimizer_cn.zero_grad()\n",
    "            # Optimize sub-network\n",
    "            outputs_sim = net(inputs)\n",
    "            net.layer1.theta.data = net.layer1.theta.data + b0_theta_error\n",
    "            net.layer1.phi.data = net.layer1.phi.data + b0_phi_error\n",
    "            net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                    torch.as_tensor(nenn_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepn_n, dtype=torch.float32).cuda(), \\\n",
    "                    torch.as_tensor(nenp_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepp_n, dtype=torch.float32).cuda()\n",
    "            outputs_phy = net.phy_forward(inputs)        \n",
    "            net.layer1.theta.data = net.layer1.theta.data - b0_theta_error\n",
    "            net.layer1.phi.data = net.layer1.phi.data - b0_phi_error\n",
    "            net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                    torch.as_tensor(nenn_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepn_init, dtype=torch.float32).cuda(), \\\n",
    "                    torch.as_tensor(nenp_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepp_init, dtype=torch.float32).cuda()  \n",
    "            \n",
    "            loss_cn = criterion_cn(outputs_sim, outputs_phy)\n",
    "            loss_cn.backward()\n",
    "            optimizer_cn.step()\n",
    "            scheduler_cn.step()\n",
    "        # Optimize Main network\n",
    "        outputs_sim = net(inputs, cn_weight) \n",
    "        with torch.no_grad():\n",
    "            net.layer1.theta.data = net.layer1.theta.data + b0_theta_error\n",
    "            net.layer1.phi.data = net.layer1.phi.data + b0_phi_error\n",
    "            net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                    torch.as_tensor(nenn_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepn_n, dtype=torch.float32).cuda(), \\\n",
    "                    torch.as_tensor(nenp_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepp_n, dtype=torch.float32).cuda() \n",
    "            outputs_phy = net.phy_forward(inputs)\n",
    "            net.phy_replace_sim()\n",
    "            outputs_sim.data.copy_(outputs_phy.data)\n",
    "            net.layer1.theta.data = net.layer1.theta.data - b0_theta_error\n",
    "            net.layer1.phi.data = net.layer1.phi.data - b0_phi_error\n",
    "            net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                    torch.as_tensor(nenn_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepn_init, dtype=torch.float32).cuda(), \\\n",
    "                    torch.as_tensor(nenp_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nepp_init, dtype=torch.float32).cuda() \n",
    "        \n",
    "        loss = criterion(outputs_sim, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        net.apply_constraints()\n",
    "        # print statistics\n",
    "        running_loss_cn += loss_cn.item()\n",
    "        running_loss += loss.item()\n",
    "        if i % 2 == 1:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] classification loss: {running_loss / 2:.3f} loss_cn: {running_loss_cn / 2:.3f}')\n",
    "            running_loss = 0.0\n",
    "            running_loss_cn = 0.0\n",
    "    scheduler.step()\n",
    "    if epoch % 10 == 9:    # print every 2000 mini-batches\n",
    "        print(f'epoch:{epoch}')\n",
    "        net.to(device)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                # calculate outputs by running images through the network\n",
    "                net.layer1.theta.data = net.layer1.theta.data + b0_theta_error\n",
    "                net.layer1.phi.data = net.layer1.phi.data + b0_phi_error\n",
    "                net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                        torch.as_tensor(nenn_n, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepn_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nenp_n, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepp_n, dtype=torch.float32).cuda()                    \n",
    "                outputs = net.phy_forward(inputs)\n",
    "                net.layer1.theta.data = net.layer1.theta.data - b0_theta_error\n",
    "                net.layer1.phi.data = net.layer1.phi.data - b0_phi_error \n",
    "                net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                        torch.as_tensor(nenn_init, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepn_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nenp_init, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepp_init, dtype=torch.float32).cuda() \n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print(f'Accuracy 10000 test images: {100 * correct / total} %')\n",
    "print('Finished Training')\n",
    "end = time.time()\n",
    "print(end-start)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     2] classification loss: 2.314 loss_cn: 0.012\n",
      "[1,     4] classification loss: 2.298 loss_cn: 0.010\n",
      "[1,     6] classification loss: 2.278 loss_cn: 0.010\n",
      "[1,     8] classification loss: 2.255 loss_cn: 0.009\n",
      "[1,    10] classification loss: 2.233 loss_cn: 0.008\n",
      "[2,     2] classification loss: 2.215 loss_cn: 0.008\n",
      "[2,     4] classification loss: 2.201 loss_cn: 0.007\n",
      "[2,     6] classification loss: 2.190 loss_cn: 0.007\n",
      "[2,     8] classification loss: 2.183 loss_cn: 0.007\n",
      "[2,    10] classification loss: 2.174 loss_cn: 0.006\n",
      "[3,     2] classification loss: 2.167 loss_cn: 0.006\n",
      "[3,     4] classification loss: 2.159 loss_cn: 0.006\n",
      "[3,     6] classification loss: 2.150 loss_cn: 0.006\n",
      "[3,     8] classification loss: 2.142 loss_cn: 0.006\n",
      "[3,    10] classification loss: 2.137 loss_cn: 0.005\n",
      "[4,     2] classification loss: 2.129 loss_cn: 0.005\n",
      "[4,     4] classification loss: 2.122 loss_cn: 0.005\n",
      "[4,     6] classification loss: 2.121 loss_cn: 0.005\n",
      "[4,     8] classification loss: 2.113 loss_cn: 0.005\n",
      "[4,    10] classification loss: 2.110 loss_cn: 0.004\n",
      "[5,     2] classification loss: 2.103 loss_cn: 0.004\n",
      "[5,     4] classification loss: 2.100 loss_cn: 0.004\n",
      "[5,     6] classification loss: 2.092 loss_cn: 0.004\n",
      "[5,     8] classification loss: 2.093 loss_cn: 0.004\n",
      "[5,    10] classification loss: 2.085 loss_cn: 0.004\n",
      "[6,     2] classification loss: 2.084 loss_cn: 0.003\n",
      "[6,     4] classification loss: 2.078 loss_cn: 0.003\n",
      "[6,     6] classification loss: 2.076 loss_cn: 0.003\n",
      "[6,     8] classification loss: 2.074 loss_cn: 0.003\n",
      "[6,    10] classification loss: 2.071 loss_cn: 0.003\n",
      "[7,     2] classification loss: 2.066 loss_cn: 0.003\n",
      "[7,     4] classification loss: 2.063 loss_cn: 0.003\n",
      "[7,     6] classification loss: 2.061 loss_cn: 0.003\n",
      "[7,     8] classification loss: 2.061 loss_cn: 0.003\n",
      "[7,    10] classification loss: 2.063 loss_cn: 0.003\n",
      "[8,     2] classification loss: 2.061 loss_cn: 0.003\n",
      "[8,     4] classification loss: 2.059 loss_cn: 0.003\n",
      "[8,     6] classification loss: 2.049 loss_cn: 0.003\n",
      "[8,     8] classification loss: 2.049 loss_cn: 0.003\n",
      "[8,    10] classification loss: 2.048 loss_cn: 0.002\n",
      "[9,     2] classification loss: 2.053 loss_cn: 0.002\n",
      "[9,     4] classification loss: 2.049 loss_cn: 0.002\n",
      "[9,     6] classification loss: 2.051 loss_cn: 0.002\n",
      "[9,     8] classification loss: 2.039 loss_cn: 0.002\n",
      "[9,    10] classification loss: 2.043 loss_cn: 0.002\n",
      "[10,     2] classification loss: 2.044 loss_cn: 0.002\n",
      "[10,     4] classification loss: 2.040 loss_cn: 0.002\n",
      "[10,     6] classification loss: 2.037 loss_cn: 0.002\n",
      "[10,     8] classification loss: 2.052 loss_cn: 0.002\n",
      "[10,    10] classification loss: 2.029 loss_cn: 0.002\n",
      "epoch:9\n",
      "Accuracy 10000 test images: 69.75 %\n",
      "[11,     2] classification loss: 2.029 loss_cn: 0.002\n",
      "[11,     4] classification loss: 2.037 loss_cn: 0.002\n",
      "[11,     6] classification loss: 2.038 loss_cn: 0.002\n",
      "[11,     8] classification loss: 2.045 loss_cn: 0.002\n",
      "[11,    10] classification loss: 2.020 loss_cn: 0.002\n",
      "[12,     2] classification loss: 2.033 loss_cn: 0.002\n",
      "[12,     4] classification loss: 2.040 loss_cn: 0.002\n",
      "[12,     6] classification loss: 2.024 loss_cn: 0.002\n",
      "[12,     8] classification loss: 2.027 loss_cn: 0.002\n",
      "[12,    10] classification loss: 2.030 loss_cn: 0.002\n",
      "[13,     2] classification loss: 2.031 loss_cn: 0.002\n",
      "[13,     4] classification loss: 2.018 loss_cn: 0.002\n",
      "[13,     6] classification loss: 2.044 loss_cn: 0.002\n",
      "[13,     8] classification loss: 2.044 loss_cn: 0.002\n",
      "[13,    10] classification loss: 2.007 loss_cn: 0.002\n",
      "[14,     2] classification loss: 2.032 loss_cn: 0.002\n",
      "[14,     4] classification loss: 2.015 loss_cn: 0.002\n",
      "[14,     6] classification loss: 2.011 loss_cn: 0.002\n",
      "[14,     8] classification loss: 2.020 loss_cn: 0.002\n",
      "[14,    10] classification loss: 2.011 loss_cn: 0.002\n",
      "[15,     2] classification loss: 2.000 loss_cn: 0.002\n",
      "[15,     4] classification loss: 1.997 loss_cn: 0.002\n",
      "[15,     6] classification loss: 2.005 loss_cn: 0.002\n",
      "[15,     8] classification loss: 2.005 loss_cn: 0.002\n",
      "[15,    10] classification loss: 2.017 loss_cn: 0.002\n",
      "[16,     2] classification loss: 2.025 loss_cn: 0.002\n",
      "[16,     4] classification loss: 2.002 loss_cn: 0.002\n",
      "[16,     6] classification loss: 2.015 loss_cn: 0.002\n",
      "[16,     8] classification loss: 2.005 loss_cn: 0.002\n",
      "[16,    10] classification loss: 2.018 loss_cn: 0.002\n",
      "[17,     2] classification loss: 2.008 loss_cn: 0.002\n",
      "[17,     4] classification loss: 1.985 loss_cn: 0.002\n",
      "[17,     6] classification loss: 2.007 loss_cn: 0.002\n",
      "[17,     8] classification loss: 2.024 loss_cn: 0.002\n",
      "[17,    10] classification loss: 2.020 loss_cn: 0.002\n",
      "[18,     2] classification loss: 2.008 loss_cn: 0.002\n",
      "[18,     4] classification loss: 1.994 loss_cn: 0.002\n",
      "[18,     6] classification loss: 1.995 loss_cn: 0.002\n",
      "[18,     8] classification loss: 2.012 loss_cn: 0.002\n",
      "[18,    10] classification loss: 2.022 loss_cn: 0.002\n",
      "[19,     2] classification loss: 1.989 loss_cn: 0.002\n",
      "[19,     4] classification loss: 2.001 loss_cn: 0.002\n",
      "[19,     6] classification loss: 2.017 loss_cn: 0.002\n",
      "[19,     8] classification loss: 2.017 loss_cn: 0.002\n",
      "[19,    10] classification loss: 1.989 loss_cn: 0.002\n",
      "[20,     2] classification loss: 2.014 loss_cn: 0.002\n",
      "[20,     4] classification loss: 2.012 loss_cn: 0.002\n",
      "[20,     6] classification loss: 1.989 loss_cn: 0.002\n",
      "[20,     8] classification loss: 2.010 loss_cn: 0.002\n",
      "[20,    10] classification loss: 1.986 loss_cn: 0.001\n",
      "epoch:19\n",
      "Accuracy 10000 test images: 73.58 %\n",
      "[21,     2] classification loss: 1.976 loss_cn: 0.001\n",
      "[21,     4] classification loss: 1.932 loss_cn: 0.001\n",
      "[21,     6] classification loss: 1.882 loss_cn: 0.001\n",
      "[21,     8] classification loss: 1.852 loss_cn: 0.001\n",
      "[21,    10] classification loss: 1.825 loss_cn: 0.001\n",
      "[22,     2] classification loss: 1.808 loss_cn: 0.001\n",
      "[22,     4] classification loss: 1.799 loss_cn: 0.001\n",
      "[22,     6] classification loss: 1.789 loss_cn: 0.001\n",
      "[22,     8] classification loss: 1.781 loss_cn: 0.001\n",
      "[22,    10] classification loss: 1.776 loss_cn: 0.001\n",
      "[23,     2] classification loss: 1.770 loss_cn: 0.001\n",
      "[23,     4] classification loss: 1.764 loss_cn: 0.001\n",
      "[23,     6] classification loss: 1.761 loss_cn: 0.001\n",
      "[23,     8] classification loss: 1.757 loss_cn: 0.001\n",
      "[23,    10] classification loss: 1.754 loss_cn: 0.001\n",
      "[24,     2] classification loss: 1.755 loss_cn: 0.001\n",
      "[24,     4] classification loss: 1.748 loss_cn: 0.001\n",
      "[24,     6] classification loss: 1.748 loss_cn: 0.001\n",
      "[24,     8] classification loss: 1.744 loss_cn: 0.001\n",
      "[24,    10] classification loss: 1.739 loss_cn: 0.001\n",
      "[25,     2] classification loss: 1.741 loss_cn: 0.001\n",
      "[25,     4] classification loss: 1.738 loss_cn: 0.001\n",
      "[25,     6] classification loss: 1.738 loss_cn: 0.001\n",
      "[25,     8] classification loss: 1.737 loss_cn: 0.001\n",
      "[25,    10] classification loss: 1.737 loss_cn: 0.001\n",
      "[26,     2] classification loss: 1.733 loss_cn: 0.001\n",
      "[26,     4] classification loss: 1.733 loss_cn: 0.001\n",
      "[26,     6] classification loss: 1.735 loss_cn: 0.001\n",
      "[26,     8] classification loss: 1.733 loss_cn: 0.001\n",
      "[26,    10] classification loss: 1.730 loss_cn: 0.001\n",
      "[27,     2] classification loss: 1.732 loss_cn: 0.001\n",
      "[27,     4] classification loss: 1.730 loss_cn: 0.001\n",
      "[27,     6] classification loss: 1.729 loss_cn: 0.001\n",
      "[27,     8] classification loss: 1.727 loss_cn: 0.001\n",
      "[27,    10] classification loss: 1.727 loss_cn: 0.001\n",
      "[28,     2] classification loss: 1.726 loss_cn: 0.001\n",
      "[28,     4] classification loss: 1.726 loss_cn: 0.001\n",
      "[28,     6] classification loss: 1.728 loss_cn: 0.001\n",
      "[28,     8] classification loss: 1.727 loss_cn: 0.001\n",
      "[28,    10] classification loss: 1.723 loss_cn: 0.001\n",
      "[29,     2] classification loss: 1.726 loss_cn: 0.001\n",
      "[29,     4] classification loss: 1.725 loss_cn: 0.001\n",
      "[29,     6] classification loss: 1.723 loss_cn: 0.001\n",
      "[29,     8] classification loss: 1.724 loss_cn: 0.001\n",
      "[29,    10] classification loss: 1.722 loss_cn: 0.001\n",
      "[30,     2] classification loss: 1.723 loss_cn: 0.001\n",
      "[30,     4] classification loss: 1.721 loss_cn: 0.001\n",
      "[30,     6] classification loss: 1.722 loss_cn: 0.001\n",
      "[30,     8] classification loss: 1.721 loss_cn: 0.001\n",
      "[30,    10] classification loss: 1.722 loss_cn: 0.001\n",
      "epoch:29\n",
      "Accuracy 10000 test images: 93.65 %\n",
      "[31,     2] classification loss: 1.720 loss_cn: 0.001\n",
      "[31,     4] classification loss: 1.721 loss_cn: 0.001\n",
      "[31,     6] classification loss: 1.721 loss_cn: 0.001\n",
      "[31,     8] classification loss: 1.722 loss_cn: 0.001\n",
      "[31,    10] classification loss: 1.721 loss_cn: 0.001\n",
      "[32,     2] classification loss: 1.719 loss_cn: 0.001\n",
      "[32,     4] classification loss: 1.721 loss_cn: 0.001\n",
      "[32,     6] classification loss: 1.721 loss_cn: 0.001\n",
      "[32,     8] classification loss: 1.720 loss_cn: 0.001\n",
      "[32,    10] classification loss: 1.719 loss_cn: 0.001\n",
      "[33,     2] classification loss: 1.718 loss_cn: 0.001\n",
      "[33,     4] classification loss: 1.721 loss_cn: 0.001\n",
      "[33,     6] classification loss: 1.719 loss_cn: 0.001\n",
      "[33,     8] classification loss: 1.719 loss_cn: 0.001\n",
      "[33,    10] classification loss: 1.719 loss_cn: 0.001\n",
      "[34,     2] classification loss: 1.718 loss_cn: 0.001\n",
      "[34,     4] classification loss: 1.721 loss_cn: 0.001\n",
      "[34,     6] classification loss: 1.717 loss_cn: 0.001\n",
      "[34,     8] classification loss: 1.718 loss_cn: 0.001\n",
      "[34,    10] classification loss: 1.719 loss_cn: 0.001\n",
      "[35,     2] classification loss: 1.719 loss_cn: 0.001\n",
      "[35,     4] classification loss: 1.718 loss_cn: 0.001\n",
      "[35,     6] classification loss: 1.714 loss_cn: 0.001\n",
      "[35,     8] classification loss: 1.718 loss_cn: 0.001\n",
      "[35,    10] classification loss: 1.722 loss_cn: 0.001\n",
      "[36,     2] classification loss: 1.717 loss_cn: 0.001\n",
      "[36,     4] classification loss: 1.717 loss_cn: 0.001\n",
      "[36,     6] classification loss: 1.717 loss_cn: 0.001\n",
      "[36,     8] classification loss: 1.718 loss_cn: 0.001\n",
      "[36,    10] classification loss: 1.720 loss_cn: 0.001\n",
      "[37,     2] classification loss: 1.720 loss_cn: 0.001\n",
      "[37,     4] classification loss: 1.718 loss_cn: 0.001\n",
      "[37,     6] classification loss: 1.719 loss_cn: 0.001\n",
      "[37,     8] classification loss: 1.717 loss_cn: 0.001\n",
      "[37,    10] classification loss: 1.712 loss_cn: 0.001\n",
      "[38,     2] classification loss: 1.717 loss_cn: 0.001\n",
      "[38,     4] classification loss: 1.714 loss_cn: 0.001\n",
      "[38,     6] classification loss: 1.718 loss_cn: 0.001\n",
      "[38,     8] classification loss: 1.720 loss_cn: 0.001\n",
      "[38,    10] classification loss: 1.716 loss_cn: 0.001\n",
      "[39,     2] classification loss: 1.717 loss_cn: 0.001\n",
      "[39,     4] classification loss: 1.717 loss_cn: 0.001\n",
      "[39,     6] classification loss: 1.718 loss_cn: 0.001\n",
      "[39,     8] classification loss: 1.716 loss_cn: 0.001\n",
      "[39,    10] classification loss: 1.715 loss_cn: 0.001\n",
      "[40,     2] classification loss: 1.717 loss_cn: 0.001\n",
      "[40,     4] classification loss: 1.717 loss_cn: 0.001\n",
      "[40,     6] classification loss: 1.714 loss_cn: 0.001\n",
      "[40,     8] classification loss: 1.716 loss_cn: 0.001\n",
      "[40,    10] classification loss: 1.717 loss_cn: 0.001\n",
      "epoch:39\n",
      "Accuracy 10000 test images: 94.21 %\n",
      "[41,     2] classification loss: 1.717 loss_cn: 0.001\n",
      "[41,     4] classification loss: 1.716 loss_cn: 0.001\n",
      "[41,     6] classification loss: 1.718 loss_cn: 0.001\n",
      "[41,     8] classification loss: 1.715 loss_cn: 0.001\n",
      "[41,    10] classification loss: 1.715 loss_cn: 0.001\n",
      "[42,     2] classification loss: 1.719 loss_cn: 0.001\n",
      "[42,     4] classification loss: 1.716 loss_cn: 0.001\n",
      "[42,     6] classification loss: 1.713 loss_cn: 0.001\n",
      "[42,     8] classification loss: 1.716 loss_cn: 0.001\n",
      "[42,    10] classification loss: 1.715 loss_cn: 0.001\n",
      "[43,     2] classification loss: 1.717 loss_cn: 0.001\n",
      "[43,     4] classification loss: 1.718 loss_cn: 0.001\n",
      "[43,     6] classification loss: 1.716 loss_cn: 0.001\n",
      "[43,     8] classification loss: 1.714 loss_cn: 0.001\n",
      "[43,    10] classification loss: 1.712 loss_cn: 0.001\n",
      "[44,     2] classification loss: 1.715 loss_cn: 0.001\n",
      "[44,     4] classification loss: 1.715 loss_cn: 0.001\n",
      "[44,     6] classification loss: 1.715 loss_cn: 0.001\n",
      "[44,     8] classification loss: 1.715 loss_cn: 0.001\n",
      "[44,    10] classification loss: 1.715 loss_cn: 0.001\n",
      "[45,     2] classification loss: 1.714 loss_cn: 0.001\n",
      "[45,     4] classification loss: 1.715 loss_cn: 0.001\n",
      "[45,     6] classification loss: 1.716 loss_cn: 0.001\n",
      "[45,     8] classification loss: 1.713 loss_cn: 0.001\n",
      "[45,    10] classification loss: 1.718 loss_cn: 0.001\n",
      "[46,     2] classification loss: 1.712 loss_cn: 0.001\n",
      "[46,     4] classification loss: 1.716 loss_cn: 0.001\n",
      "[46,     6] classification loss: 1.717 loss_cn: 0.001\n",
      "[46,     8] classification loss: 1.714 loss_cn: 0.001\n",
      "[46,    10] classification loss: 1.715 loss_cn: 0.001\n",
      "[47,     2] classification loss: 1.715 loss_cn: 0.001\n",
      "[47,     4] classification loss: 1.714 loss_cn: 0.001\n",
      "[47,     6] classification loss: 1.715 loss_cn: 0.001\n",
      "[47,     8] classification loss: 1.713 loss_cn: 0.001\n",
      "[47,    10] classification loss: 1.715 loss_cn: 0.001\n",
      "[48,     2] classification loss: 1.716 loss_cn: 0.001\n",
      "[48,     4] classification loss: 1.713 loss_cn: 0.001\n",
      "[48,     6] classification loss: 1.714 loss_cn: 0.001\n",
      "[48,     8] classification loss: 1.715 loss_cn: 0.001\n",
      "[48,    10] classification loss: 1.715 loss_cn: 0.001\n",
      "[49,     2] classification loss: 1.717 loss_cn: 0.001\n",
      "[49,     4] classification loss: 1.713 loss_cn: 0.001\n",
      "[49,     6] classification loss: 1.713 loss_cn: 0.001\n",
      "[49,     8] classification loss: 1.712 loss_cn: 0.001\n",
      "[49,    10] classification loss: 1.717 loss_cn: 0.001\n",
      "[50,     2] classification loss: 1.716 loss_cn: 0.001\n",
      "[50,     4] classification loss: 1.712 loss_cn: 0.001\n",
      "[50,     6] classification loss: 1.714 loss_cn: 0.001\n",
      "[50,     8] classification loss: 1.715 loss_cn: 0.001\n",
      "[50,    10] classification loss: 1.715 loss_cn: 0.001\n",
      "epoch:49\n",
      "Accuracy 10000 test images: 94.44 %\n",
      "[51,     2] classification loss: 1.712 loss_cn: 0.001\n",
      "[51,     4] classification loss: 1.716 loss_cn: 0.001\n",
      "[51,     6] classification loss: 1.712 loss_cn: 0.001\n",
      "[51,     8] classification loss: 1.717 loss_cn: 0.001\n",
      "[51,    10] classification loss: 1.714 loss_cn: 0.001\n",
      "[52,     2] classification loss: 1.716 loss_cn: 0.001\n",
      "[52,     4] classification loss: 1.714 loss_cn: 0.001\n",
      "[52,     6] classification loss: 1.714 loss_cn: 0.001\n",
      "[52,     8] classification loss: 1.715 loss_cn: 0.001\n",
      "[52,    10] classification loss: 1.712 loss_cn: 0.001\n",
      "[53,     2] classification loss: 1.711 loss_cn: 0.001\n",
      "[53,     4] classification loss: 1.714 loss_cn: 0.001\n",
      "[53,     6] classification loss: 1.714 loss_cn: 0.001\n",
      "[53,     8] classification loss: 1.716 loss_cn: 0.001\n",
      "[53,    10] classification loss: 1.717 loss_cn: 0.001\n",
      "[54,     2] classification loss: 1.714 loss_cn: 0.001\n",
      "[54,     4] classification loss: 1.715 loss_cn: 0.001\n",
      "[54,     6] classification loss: 1.715 loss_cn: 0.001\n",
      "[54,     8] classification loss: 1.715 loss_cn: 0.001\n",
      "[54,    10] classification loss: 1.711 loss_cn: 0.001\n",
      "[55,     2] classification loss: 1.713 loss_cn: 0.001\n",
      "[55,     4] classification loss: 1.714 loss_cn: 0.001\n",
      "[55,     6] classification loss: 1.716 loss_cn: 0.001\n",
      "[55,     8] classification loss: 1.714 loss_cn: 0.001\n",
      "[55,    10] classification loss: 1.712 loss_cn: 0.001\n",
      "[56,     2] classification loss: 1.712 loss_cn: 0.001\n",
      "[56,     4] classification loss: 1.713 loss_cn: 0.001\n",
      "[56,     6] classification loss: 1.713 loss_cn: 0.001\n",
      "[56,     8] classification loss: 1.716 loss_cn: 0.001\n",
      "[56,    10] classification loss: 1.715 loss_cn: 0.001\n",
      "[57,     2] classification loss: 1.713 loss_cn: 0.001\n",
      "[57,     4] classification loss: 1.713 loss_cn: 0.001\n",
      "[57,     6] classification loss: 1.716 loss_cn: 0.001\n",
      "[57,     8] classification loss: 1.712 loss_cn: 0.001\n",
      "[57,    10] classification loss: 1.714 loss_cn: 0.001\n",
      "[58,     2] classification loss: 1.714 loss_cn: 0.001\n",
      "[58,     4] classification loss: 1.714 loss_cn: 0.001\n",
      "[58,     6] classification loss: 1.712 loss_cn: 0.001\n",
      "[58,     8] classification loss: 1.716 loss_cn: 0.001\n",
      "[58,    10] classification loss: 1.713 loss_cn: 0.001\n",
      "[59,     2] classification loss: 1.712 loss_cn: 0.001\n",
      "[59,     4] classification loss: 1.712 loss_cn: 0.001\n",
      "[59,     6] classification loss: 1.714 loss_cn: 0.001\n",
      "[59,     8] classification loss: 1.715 loss_cn: 0.001\n",
      "[59,    10] classification loss: 1.716 loss_cn: 0.001\n",
      "[60,     2] classification loss: 1.712 loss_cn: 0.001\n",
      "[60,     4] classification loss: 1.715 loss_cn: 0.001\n",
      "[60,     6] classification loss: 1.714 loss_cn: 0.001\n",
      "[60,     8] classification loss: 1.712 loss_cn: 0.001\n",
      "[60,    10] classification loss: 1.716 loss_cn: 0.001\n",
      "epoch:59\n",
      "Accuracy 10000 test images: 94.64 %\n",
      "Finished Training\n",
      "1272.738394021988\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "9c5e8a89fddc1d5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T10:00:42.707719Z",
     "start_time": "2025-06-05T10:00:42.666961Z"
    }
   },
   "source": [
    "PATH = './Training Results/05-DAT.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "PATH = ''"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "7a844ef3",
   "metadata": {},
   "source": [
    "### 06-NAT"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T11:45:44.583537Z",
     "start_time": "2025-06-05T11:45:44.553676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 64)\n",
    "        self.norm1 = nn.BatchNorm2d(6)\n",
    "        self.norm2 = nn.BatchNorm2d(16)\n",
    "        self.norm3 = nn.BatchNorm1d(120)\n",
    "        self.layer1 = RMTorch(64, phase_error = 0, phase_error_files = None,bs_error=0,bs_error_files = None)\n",
    "        self.output = CNormSq()\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = F.max_pool2d(F.relu(self.norm1(self.conv1(x))), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.norm2(self.conv2(x))), (2, 2))\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.fc1(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.stack((x, torch.zeros(x.shape, dtype=torch.float32, device=x.device)), dim=0)\n",
    "        x,_,_,_ = self.layer1(x)\n",
    "        x = self.output(x)\n",
    "        self.at_sensor_intensity = x\n",
    "        return self.at_sensor_intensity[:,:10]\n",
    "    \n",
    "    def phy_forward(self,x):\n",
    "        self.in_outs_phy = []\n",
    "        with torch.no_grad():\n",
    "            x = F.max_pool2d(F.relu(self.norm1(self.conv1(x))), (2, 2))\n",
    "            x = F.max_pool2d(F.relu(self.norm2(self.conv2(x))), (2, 2))\n",
    "            x = x.view(x.size(0), -1) \n",
    "            x = self.fc1(x)\n",
    "            x = self.norm3(x)\n",
    "            x = self.fc2(x)\n",
    "            x = torch.stack((x, torch.zeros(x.shape, dtype=torch.float32, device=x.device)), dim=0)\n",
    "            x, _, _, _ = self.layer1(x)\n",
    "            x = self.output(x)\n",
    "            self.at_sensor_intensity_phy = x\n",
    "        return self.at_sensor_intensity_phy[:,:10]    \n",
    "    \n",
    "    def phy_replace_sim(self):\n",
    "        # PAT: replace the output\n",
    "        with torch.no_grad():\n",
    "            self.at_sensor_intensity.data.copy_(self.at_sensor_intensity_phy.data)    \n",
    "\n",
    "    def apply_constraints(self):\n",
    "        self.conv1.cuda().weight.data = torch.clamp(self.conv1.cuda().weight.data, -1, 1)\n",
    "        self.conv2.cuda().weight.data = torch.clamp(self.conv2.cuda().weight.data, -1, 1)\n",
    "        self.fc1.cuda().weight.data = torch.clamp(self.fc1.cuda().weight.data, -1, 1)\n",
    "        self.fc2.cuda().weight.data = torch.clamp(self.fc2.cuda().weight.data, -1, 1)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "net = LeNet5()\n",
    "net.to(device)"
   ],
   "id": "96fc35ec437738f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=64, bias=True)\n",
       "  (norm1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm3): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): RMTorch()\n",
       "  (output): CNormSq()\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "02a0f466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T11:45:45.240332Z",
     "start_time": "2025-06-05T11:45:45.219657Z"
    }
   },
   "source": [
    "import torch.optim as optim\n",
    "net = LeNet5()\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 400, gamma = 0.5)"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "bdd84058",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T11:51:24.273450Z",
     "start_time": "2025-06-05T11:45:46.049120Z"
    }
   },
   "source": [
    "import time\n",
    "net.to(device)\n",
    "start = time.time()\n",
    "for epoch in range(40):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        # Add noise\n",
    "        net.layer1.mesh_model.bs_error = 0.01\n",
    "        [nenn, nepn, nenp, nepp], [enn, epn, enp, epp] = net.layer1.mesh_model.mzi_error_tensors()\n",
    "        net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                            torch.as_tensor(enn, dtype=torch.float32).cuda(), \\\n",
    "                                torch.as_tensor(epn, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(enp, dtype=torch.float32).cuda(), \\\n",
    "                                torch.as_tensor(epp, dtype=torch.float32).cuda()\n",
    "        b0_theta_error_random = torch.randn(net.layer1.theta.shape).cuda() * 0.01\n",
    "        b0_phi_error_random = torch.randn(net.layer1.phi.shape).cuda() * 0.01\n",
    "        outputs_sim = net(inputs)\n",
    "\n",
    "        net.layer1.theta.data = net.layer1.theta.data - b0_theta_error_random\n",
    "        net.layer1.phi.data = net.layer1.phi.data - b0_phi_error_random  \n",
    "        net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                torch.as_tensor(nenn_init, dtype=torch.float32).cuda(), \\\n",
    "                    torch.as_tensor(nepn_init, dtype=torch.float32).cuda(), \\\n",
    "                torch.as_tensor(nenp_init, dtype=torch.float32).cuda(), \\\n",
    "                    torch.as_tensor(nepp_init, dtype=torch.float32).cuda() \n",
    "\n",
    "        loss0 = criterion(outputs_sim, labels)\n",
    "        loss = loss0\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        net.apply_constraints()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2 == 1:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2:.3f} Classification loss:{loss0.cpu().detach().numpy():.3f}')\n",
    "            running_loss = 0.0\n",
    "    scheduler.step()\n",
    "    if epoch % 10 == 9:    # print every 2000 mini-batches\n",
    "        print(f'epoch:{epoch}')\n",
    "        net.to(device)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                # calculate outputs by running images through the network\n",
    "                net.layer1.theta.data = net.layer1.theta.data + b0_theta_error\n",
    "                net.layer1.phi.data = net.layer1.phi.data + b0_phi_error\n",
    "                net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                        torch.as_tensor(nenn_n, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepn_n, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nenp_n, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepp_n, dtype=torch.float32).cuda()                \n",
    "                outputs = net.phy_forward(inputs)\n",
    "                net.layer1.theta.data = net.layer1.theta.data - b0_theta_error\n",
    "                net.layer1.phi.data = net.layer1.phi.data - b0_phi_error  \n",
    "                net.layer1.nenn, net.layer1.nepn, net.layer1.nenp, net.layer1.nepp = \\\n",
    "                        torch.as_tensor(nenn_init, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepn_init, dtype=torch.float32).cuda(), \\\n",
    "                        torch.as_tensor(nenp_init, dtype=torch.float32).cuda(), \\\n",
    "                            torch.as_tensor(nepp_init, dtype=torch.float32).cuda()   \n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print(f'Accuracy 10000 test images: {100 * correct / total} %')\n",
    "        accu_wo_n = 100 * correct / total\n",
    "print('Finished Training')\n",
    "end = time.time()\n",
    "print(end-start)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     2] loss: 2.289 Classification loss:2.272\n",
      "[1,     4] loss: 2.185 Classification loss:2.153\n",
      "[1,     6] loss: 2.061 Classification loss:2.026\n",
      "[1,     8] loss: 1.957 Classification loss:1.942\n",
      "[1,    10] loss: 1.878 Classification loss:1.865\n",
      "[2,     2] loss: 1.824 Classification loss:1.811\n",
      "[2,     4] loss: 1.784 Classification loss:1.776\n",
      "[2,     6] loss: 1.763 Classification loss:1.760\n",
      "[2,     8] loss: 1.740 Classification loss:1.734\n",
      "[2,    10] loss: 1.718 Classification loss:1.713\n",
      "[3,     2] loss: 1.703 Classification loss:1.699\n",
      "[3,     4] loss: 1.688 Classification loss:1.685\n",
      "[3,     6] loss: 1.678 Classification loss:1.671\n",
      "[3,     8] loss: 1.666 Classification loss:1.666\n",
      "[3,    10] loss: 1.656 Classification loss:1.654\n",
      "[4,     2] loss: 1.648 Classification loss:1.648\n",
      "[4,     4] loss: 1.639 Classification loss:1.636\n",
      "[4,     6] loss: 1.630 Classification loss:1.628\n",
      "[4,     8] loss: 1.627 Classification loss:1.624\n",
      "[4,    10] loss: 1.620 Classification loss:1.619\n",
      "[5,     2] loss: 1.613 Classification loss:1.611\n",
      "[5,     4] loss: 1.610 Classification loss:1.610\n",
      "[5,     6] loss: 1.607 Classification loss:1.606\n",
      "[5,     8] loss: 1.602 Classification loss:1.602\n",
      "[5,    10] loss: 1.597 Classification loss:1.597\n",
      "[6,     2] loss: 1.592 Classification loss:1.592\n",
      "[6,     4] loss: 1.591 Classification loss:1.589\n",
      "[6,     6] loss: 1.588 Classification loss:1.589\n",
      "[6,     8] loss: 1.587 Classification loss:1.587\n",
      "[6,    10] loss: 1.586 Classification loss:1.587\n",
      "[7,     2] loss: 1.580 Classification loss:1.577\n",
      "[7,     4] loss: 1.582 Classification loss:1.582\n",
      "[7,     6] loss: 1.578 Classification loss:1.576\n",
      "[7,     8] loss: 1.579 Classification loss:1.577\n",
      "[7,    10] loss: 1.574 Classification loss:1.576\n",
      "[8,     2] loss: 1.574 Classification loss:1.575\n",
      "[8,     4] loss: 1.574 Classification loss:1.573\n",
      "[8,     6] loss: 1.570 Classification loss:1.569\n",
      "[8,     8] loss: 1.572 Classification loss:1.572\n",
      "[8,    10] loss: 1.569 Classification loss:1.571\n",
      "[9,     2] loss: 1.568 Classification loss:1.566\n",
      "[9,     4] loss: 1.566 Classification loss:1.567\n",
      "[9,     6] loss: 1.567 Classification loss:1.564\n",
      "[9,     8] loss: 1.564 Classification loss:1.564\n",
      "[9,    10] loss: 1.563 Classification loss:1.564\n",
      "[10,     2] loss: 1.562 Classification loss:1.562\n",
      "[10,     4] loss: 1.563 Classification loss:1.562\n",
      "[10,     6] loss: 1.562 Classification loss:1.562\n",
      "[10,     8] loss: 1.559 Classification loss:1.556\n",
      "[10,    10] loss: 1.560 Classification loss:1.561\n",
      "epoch:9\n",
      "Accuracy 10000 test images: 71.08 %\n",
      "[11,     2] loss: 1.558 Classification loss:1.558\n",
      "[11,     4] loss: 1.557 Classification loss:1.557\n",
      "[11,     6] loss: 1.555 Classification loss:1.555\n",
      "[11,     8] loss: 1.556 Classification loss:1.556\n",
      "[11,    10] loss: 1.554 Classification loss:1.553\n",
      "[12,     2] loss: 1.553 Classification loss:1.554\n",
      "[12,     4] loss: 1.551 Classification loss:1.549\n",
      "[12,     6] loss: 1.550 Classification loss:1.551\n",
      "[12,     8] loss: 1.551 Classification loss:1.550\n",
      "[12,    10] loss: 1.550 Classification loss:1.549\n",
      "[13,     2] loss: 1.547 Classification loss:1.546\n",
      "[13,     4] loss: 1.549 Classification loss:1.546\n",
      "[13,     6] loss: 1.548 Classification loss:1.546\n",
      "[13,     8] loss: 1.545 Classification loss:1.548\n",
      "[13,    10] loss: 1.545 Classification loss:1.544\n",
      "[14,     2] loss: 1.545 Classification loss:1.545\n",
      "[14,     4] loss: 1.546 Classification loss:1.546\n",
      "[14,     6] loss: 1.545 Classification loss:1.545\n",
      "[14,     8] loss: 1.542 Classification loss:1.544\n",
      "[14,    10] loss: 1.540 Classification loss:1.539\n",
      "[15,     2] loss: 1.541 Classification loss:1.540\n",
      "[15,     4] loss: 1.541 Classification loss:1.541\n",
      "[15,     6] loss: 1.542 Classification loss:1.543\n",
      "[15,     8] loss: 1.541 Classification loss:1.542\n",
      "[15,    10] loss: 1.540 Classification loss:1.538\n",
      "[16,     2] loss: 1.538 Classification loss:1.539\n",
      "[16,     4] loss: 1.540 Classification loss:1.538\n",
      "[16,     6] loss: 1.542 Classification loss:1.541\n",
      "[16,     8] loss: 1.539 Classification loss:1.540\n",
      "[16,    10] loss: 1.538 Classification loss:1.539\n",
      "[17,     2] loss: 1.538 Classification loss:1.538\n",
      "[17,     4] loss: 1.540 Classification loss:1.539\n",
      "[17,     6] loss: 1.538 Classification loss:1.537\n",
      "[17,     8] loss: 1.536 Classification loss:1.537\n",
      "[17,    10] loss: 1.539 Classification loss:1.540\n",
      "[18,     2] loss: 1.535 Classification loss:1.536\n",
      "[18,     4] loss: 1.536 Classification loss:1.536\n",
      "[18,     6] loss: 1.535 Classification loss:1.534\n",
      "[18,     8] loss: 1.536 Classification loss:1.534\n",
      "[18,    10] loss: 1.537 Classification loss:1.536\n",
      "[19,     2] loss: 1.538 Classification loss:1.537\n",
      "[19,     4] loss: 1.536 Classification loss:1.535\n",
      "[19,     6] loss: 1.536 Classification loss:1.536\n",
      "[19,     8] loss: 1.533 Classification loss:1.535\n",
      "[19,    10] loss: 1.536 Classification loss:1.536\n",
      "[20,     2] loss: 1.535 Classification loss:1.533\n",
      "[20,     4] loss: 1.534 Classification loss:1.533\n",
      "[20,     6] loss: 1.532 Classification loss:1.533\n",
      "[20,     8] loss: 1.536 Classification loss:1.537\n",
      "[20,    10] loss: 1.536 Classification loss:1.536\n",
      "epoch:19\n",
      "Accuracy 10000 test images: 81.41 %\n",
      "[21,     2] loss: 1.533 Classification loss:1.534\n",
      "[21,     4] loss: 1.534 Classification loss:1.535\n",
      "[21,     6] loss: 1.533 Classification loss:1.534\n",
      "[21,     8] loss: 1.531 Classification loss:1.530\n",
      "[21,    10] loss: 1.531 Classification loss:1.532\n",
      "[22,     2] loss: 1.530 Classification loss:1.530\n",
      "[22,     4] loss: 1.531 Classification loss:1.532\n",
      "[22,     6] loss: 1.532 Classification loss:1.531\n",
      "[22,     8] loss: 1.532 Classification loss:1.531\n",
      "[22,    10] loss: 1.531 Classification loss:1.529\n",
      "[23,     2] loss: 1.530 Classification loss:1.531\n",
      "[23,     4] loss: 1.531 Classification loss:1.532\n",
      "[23,     6] loss: 1.531 Classification loss:1.534\n",
      "[23,     8] loss: 1.531 Classification loss:1.531\n",
      "[23,    10] loss: 1.533 Classification loss:1.532\n",
      "[24,     2] loss: 1.531 Classification loss:1.531\n",
      "[24,     4] loss: 1.530 Classification loss:1.529\n",
      "[24,     6] loss: 1.529 Classification loss:1.530\n",
      "[24,     8] loss: 1.531 Classification loss:1.530\n",
      "[24,    10] loss: 1.528 Classification loss:1.529\n",
      "[25,     2] loss: 1.527 Classification loss:1.528\n",
      "[25,     4] loss: 1.529 Classification loss:1.527\n",
      "[25,     6] loss: 1.526 Classification loss:1.525\n",
      "[25,     8] loss: 1.528 Classification loss:1.527\n",
      "[25,    10] loss: 1.528 Classification loss:1.529\n",
      "[26,     2] loss: 1.530 Classification loss:1.532\n",
      "[26,     4] loss: 1.526 Classification loss:1.527\n",
      "[26,     6] loss: 1.527 Classification loss:1.525\n",
      "[26,     8] loss: 1.527 Classification loss:1.526\n",
      "[26,    10] loss: 1.527 Classification loss:1.528\n",
      "[27,     2] loss: 1.527 Classification loss:1.526\n",
      "[27,     4] loss: 1.527 Classification loss:1.526\n",
      "[27,     6] loss: 1.526 Classification loss:1.527\n",
      "[27,     8] loss: 1.527 Classification loss:1.525\n",
      "[27,    10] loss: 1.525 Classification loss:1.524\n",
      "[28,     2] loss: 1.526 Classification loss:1.525\n",
      "[28,     4] loss: 1.525 Classification loss:1.526\n",
      "[28,     6] loss: 1.526 Classification loss:1.528\n",
      "[28,     8] loss: 1.524 Classification loss:1.524\n",
      "[28,    10] loss: 1.525 Classification loss:1.525\n",
      "[29,     2] loss: 1.524 Classification loss:1.523\n",
      "[29,     4] loss: 1.524 Classification loss:1.523\n",
      "[29,     6] loss: 1.526 Classification loss:1.525\n",
      "[29,     8] loss: 1.526 Classification loss:1.527\n",
      "[29,    10] loss: 1.524 Classification loss:1.523\n",
      "[30,     2] loss: 1.522 Classification loss:1.522\n",
      "[30,     4] loss: 1.522 Classification loss:1.524\n",
      "[30,     6] loss: 1.525 Classification loss:1.524\n",
      "[30,     8] loss: 1.523 Classification loss:1.523\n",
      "[30,    10] loss: 1.524 Classification loss:1.523\n",
      "epoch:29\n",
      "Accuracy 10000 test images: 73.85 %\n",
      "[31,     2] loss: 1.522 Classification loss:1.523\n",
      "[31,     4] loss: 1.522 Classification loss:1.523\n",
      "[31,     6] loss: 1.524 Classification loss:1.525\n",
      "[31,     8] loss: 1.523 Classification loss:1.521\n",
      "[31,    10] loss: 1.524 Classification loss:1.525\n",
      "[32,     2] loss: 1.522 Classification loss:1.522\n",
      "[32,     4] loss: 1.523 Classification loss:1.522\n",
      "[32,     6] loss: 1.524 Classification loss:1.523\n",
      "[32,     8] loss: 1.524 Classification loss:1.525\n",
      "[32,    10] loss: 1.521 Classification loss:1.519\n",
      "[33,     2] loss: 1.521 Classification loss:1.521\n",
      "[33,     4] loss: 1.522 Classification loss:1.522\n",
      "[33,     6] loss: 1.523 Classification loss:1.522\n",
      "[33,     8] loss: 1.521 Classification loss:1.521\n",
      "[33,    10] loss: 1.521 Classification loss:1.519\n",
      "[34,     2] loss: 1.519 Classification loss:1.519\n",
      "[34,     4] loss: 1.519 Classification loss:1.519\n",
      "[34,     6] loss: 1.523 Classification loss:1.525\n",
      "[34,     8] loss: 1.522 Classification loss:1.522\n",
      "[34,    10] loss: 1.521 Classification loss:1.522\n",
      "[35,     2] loss: 1.522 Classification loss:1.523\n",
      "[35,     4] loss: 1.521 Classification loss:1.520\n",
      "[35,     6] loss: 1.521 Classification loss:1.522\n",
      "[35,     8] loss: 1.520 Classification loss:1.520\n",
      "[35,    10] loss: 1.520 Classification loss:1.521\n",
      "[36,     2] loss: 1.520 Classification loss:1.519\n",
      "[36,     4] loss: 1.520 Classification loss:1.519\n",
      "[36,     6] loss: 1.519 Classification loss:1.520\n",
      "[36,     8] loss: 1.521 Classification loss:1.520\n",
      "[36,    10] loss: 1.522 Classification loss:1.523\n",
      "[37,     2] loss: 1.519 Classification loss:1.520\n",
      "[37,     4] loss: 1.521 Classification loss:1.519\n",
      "[37,     6] loss: 1.520 Classification loss:1.521\n",
      "[37,     8] loss: 1.519 Classification loss:1.519\n",
      "[37,    10] loss: 1.518 Classification loss:1.518\n",
      "[38,     2] loss: 1.518 Classification loss:1.518\n",
      "[38,     4] loss: 1.518 Classification loss:1.519\n",
      "[38,     6] loss: 1.520 Classification loss:1.522\n",
      "[38,     8] loss: 1.519 Classification loss:1.519\n",
      "[38,    10] loss: 1.518 Classification loss:1.519\n",
      "[39,     2] loss: 1.517 Classification loss:1.517\n",
      "[39,     4] loss: 1.518 Classification loss:1.519\n",
      "[39,     6] loss: 1.519 Classification loss:1.519\n",
      "[39,     8] loss: 1.521 Classification loss:1.521\n",
      "[39,    10] loss: 1.518 Classification loss:1.517\n",
      "[40,     2] loss: 1.518 Classification loss:1.518\n",
      "[40,     4] loss: 1.519 Classification loss:1.518\n",
      "[40,     6] loss: 1.519 Classification loss:1.520\n",
      "[40,     8] loss: 1.518 Classification loss:1.519\n",
      "[40,    10] loss: 1.519 Classification loss:1.518\n",
      "epoch:39\n",
      "Accuracy 10000 test images: 79.77 %\n",
      "Finished Training\n",
      "338.20387530326843\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "3d66bd2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T11:51:32.373360Z",
     "start_time": "2025-06-05T11:51:32.363259Z"
    }
   },
   "source": [
    "PATH = './Training Results/06-NAT.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "PATH = ''"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92da1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
