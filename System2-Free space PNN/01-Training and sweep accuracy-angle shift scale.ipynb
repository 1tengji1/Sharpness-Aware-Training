{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:16.989558Z",
     "start_time": "2025-05-30T04:48:13.704238Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\GPU_Pytorchpy39\\lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "import angular_spectrum_tensor_v1 as AST\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "import mydata\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5c8a79f6b2a84f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:22.074787Z",
     "start_time": "2025-05-30T04:48:20.760652Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Hyper parameters \"\"\"\n",
    "\n",
    "# training parameters\n",
    "Device=torch.device('cuda' if torch.cuda.is_available() else'cpu')\n",
    "batch_size = 64\n",
    "learning_rate=3e-3\n",
    "epochs=30\n",
    "\n",
    "# physical parameters\n",
    "\n",
    "lambda_0=532e-3\n",
    "\n",
    "\n",
    "def Microscope_equiv(res,F,Lmeasure,lambda_0=0.532):\n",
    "    \"\"\"transform a microscope system into a single lens\"\"\"\n",
    "    din=Lmeasure/(1+F)# euqvalient din by measurement\n",
    "    dout=din*F\n",
    "    D_equal=(1.22*lambda_0/res)*din #the equavalient D\n",
    "    f_equal=1/(1/din+1/dout)\n",
    "    return D_equal,f_equal\n",
    "\n",
    "res=5 #system resolution\n",
    "lamda_0=0.532\n",
    "FF=1\n",
    "Lmeasure=500e3\n",
    "\n",
    "[D1,f1]=Microscope_equiv(res,FF,Lmeasure)\n",
    "res=8 #system resolution\n",
    "lamda_0=0.532\n",
    "#F=1\n",
    "FF=1\n",
    "\n",
    "Lmeasure=400e3\n",
    "[D2,f2]=Microscope_equiv(res,FF,Lmeasure)\n",
    "\n",
    "\n",
    "\n",
    "mask1=AST.create_unit_mask_2D(3*32,4*2*30)\n",
    "mask2=AST.create_unit_mask_2D(3*32,4*2*30)\n",
    "\n",
    "Bool_mask1=AST.create_Binary_mask_2D(3*32,4*2*30)\n",
    "Bool_mask2=AST.create_Binary_mask_2D(3*32,4*2*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcd2e46f1b1c2423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:23.101990Z",
     "start_time": "2025-05-30T04:48:23.089245Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name='xoyr+dark_new'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b727aa27ed6c9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### change the injection level by tuning the magnitude of NL_ys(2) or NL_xs(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "583d816cf3f57b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:23.818100Z",
     "start_time": "2025-05-30T04:48:23.808747Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as F_vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87c9e6585b896e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:25.437714Z",
     "start_time": "2025-05-30T04:48:25.429740Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" forward,layer 1 \"\"\"\n",
    "angle = 0\n",
    "shift_y = 0\n",
    "scale = 1\n",
    "def f_wn_1(x,theta):\n",
    "        \"\"\"  weight transformation \"\"\"\n",
    "        w1_temp = AST.MiddlePicture_single_tensor(theta,mask1)\n",
    "        w1_temp = (F_vision.affine(w1_temp, angle=angle, translate=(0,shift_y), scale=scale, shear=0.0))        \n",
    "        w1_temp=AST.MiddlePicture2Vector(w1_temp).to(Device)\n",
    "        x = torch.matmul(x,w1_temp).to(Device)\n",
    "        return x\n",
    "\"\"\" forward,layer 2\"\"\"\n",
    "def f_wn_2(x,theta):\n",
    "        \"\"\"  weight transformation \"\"\"\n",
    "        w2_temp=AST.BigPicture_single_tensor_2D(theta,mask2,RawNumber=3,ColumnNumber=4,paddcol=30,paddraw=32,dim_in=12,num_out=10)\n",
    "        w2_temp = (F_vision.affine(w2_temp.unsqueeze(0), angle=0, translate=(0,0), scale=scale, shear=0.0))        \n",
    "        w2_temp=AST.BigPicture2Vector_2D(w2_temp,RawNumber=3,ColumnNumber=4,paddcol=30,paddraw=32,dim_in=12,num_out=10).to(Device)\n",
    "        w2_temp = w2_temp.squeeze(0)\n",
    "        x=torch.matmul(x,w2_temp).to(Device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80602f290a93d49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:26.182991Z",
     "start_time": "2025-05-30T04:48:26.162993Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Define NN class\"\"\"\n",
    "class InCoFCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InCoFCNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 144)\n",
    "        self.fc2 = nn.Linear(144, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = f_wn_1(x,self.fc1.weight.t())+self.fc1.bias\n",
    "        x = F.sigmoid(x)\n",
    "        x = f_wn_2(x,self.fc2.weight.t())+self.fc2.bias\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def apply_constraints(self):\n",
    "        self.fc1.weight.data = torch.clamp(self.fc1.weight.data,-1,1)        \n",
    "        self.fc2.weight.data = torch.clamp(self.fc2.weight.data,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "484ca3d3cc6cb9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:27.175316Z",
     "start_time": "2025-05-30T04:48:27.121987Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" data loading \"\"\"\n",
    "transform0 = transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081,))])\n",
    "\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform0)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b62c5f65af6f566",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:48:28.643748Z",
     "start_time": "2025-05-30T04:48:28.638824Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = InCoFCNet().to(Device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(net.parameters(),lr=learning_rate*0.5,betas=(0.9,0.999))\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99802fceace47fbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T04:58:21.683767Z",
     "start_time": "2025-05-30T04:48:31.729215Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Standard BP\"\"\"\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "        inputs = inputs.view(inputs.size(0), -1).to(Device)  # 将输入数据展平\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        net.apply_constraints()      \n",
    "        running_loss += loss.item()\n",
    "        if i % 600 == 599:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 600:.3f} Classification loss:{loss.cpu().detach().numpy():.3f}')\n",
    "            running_loss = 0.0\n",
    "    scheduler.step()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "            inputs = inputs.view(inputs.size(0), -1) \n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(inputs)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy 10000 test images: {100 * correct / total} %')\n",
    "print('Finished Training')\n",
    "y_pred = []\n",
    "t_pred = []\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "    inputs = inputs.view(-1, 784)\n",
    "    # calculate outputs by running images through the network\n",
    "    outputs = net(inputs)\n",
    "    # the class with the highest energy is what we choose as prediction\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    y = predicted.view(-1).cpu().detach().numpy()\n",
    "    t = labels.view(-1).cpu().detach().numpy()\n",
    "    for i in range(len(predicted)):\n",
    "        y_pred.append(y[i])\n",
    "        t_pred.append(t[i])\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print(f'W noise Accuracy 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9327bbe90b153681",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:00:22.469216Z",
     "start_time": "2025-05-30T05:00:22.461965Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net_ref=net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "113cbae551f37dbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:00:23.280705Z",
     "start_time": "2025-05-30T05:00:23.264226Z"
    }
   },
   "outputs": [],
   "source": [
    "from sam import SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "548e45a789dddf90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:00:23.733164Z",
     "start_time": "2025-05-30T05:00:23.724352Z"
    }
   },
   "outputs": [],
   "source": [
    "net = InCoFCNet().to(Device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "base_optimizer = torch.optim.Adam\n",
    "optimizer = SAM(net.parameters(), rho=0.3, base_optimizer=base_optimizer,lr=1e-3,adaptive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a81bc956f5ec67ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:13:28.089304Z",
     "start_time": "2025-05-30T05:00:24.228226Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 0.888 Classification loss:0.472 angle_grad:0.029 shift_y_grad:0.000 scale_grad:31.822\n",
      "[1,   600] loss: 0.381 Classification loss:0.410 angle_grad:0.085 shift_y_grad:0.000 scale_grad:38.887\n",
      "[1,   900] loss: 0.302 Classification loss:0.215 angle_grad:0.000 shift_y_grad:0.246 scale_grad:32.778\n",
      "Accuracy 10000 test images: 92.43 %\n",
      "[2,   300] loss: 0.252 Classification loss:0.219 angle_grad:0.022 shift_y_grad:0.000 scale_grad:37.951\n",
      "[2,   600] loss: 0.226 Classification loss:0.311 angle_grad:0.000 shift_y_grad:-0.006 scale_grad:35.705\n",
      "[2,   900] loss: 0.207 Classification loss:0.150 angle_grad:0.025 shift_y_grad:0.000 scale_grad:111.381\n",
      "Accuracy 10000 test images: 94.64 %\n",
      "[3,   300] loss: 0.181 Classification loss:0.157 angle_grad:0.016 shift_y_grad:0.000 scale_grad:1.241\n",
      "[3,   600] loss: 0.171 Classification loss:0.239 angle_grad:0.020 shift_y_grad:-0.033 scale_grad:21.808\n",
      "[3,   900] loss: 0.165 Classification loss:0.110 angle_grad:0.000 shift_y_grad:0.129 scale_grad:24.471\n",
      "Accuracy 10000 test images: 95.57 %\n",
      "[4,   300] loss: 0.146 Classification loss:0.120 angle_grad:-0.000 shift_y_grad:0.000 scale_grad:37.133\n",
      "[4,   600] loss: 0.144 Classification loss:0.232 angle_grad:0.004 shift_y_grad:-0.029 scale_grad:0.000\n",
      "[4,   900] loss: 0.139 Classification loss:0.094 angle_grad:0.038 shift_y_grad:0.040 scale_grad:12.916\n",
      "Accuracy 10000 test images: 96.2 %\n",
      "[5,   300] loss: 0.123 Classification loss:0.097 angle_grad:0.000 shift_y_grad:0.000 scale_grad:23.705\n",
      "[5,   600] loss: 0.124 Classification loss:0.168 angle_grad:0.000 shift_y_grad:-0.025 scale_grad:59.455\n",
      "[5,   900] loss: 0.120 Classification loss:0.080 angle_grad:0.008 shift_y_grad:-0.033 scale_grad:27.843\n",
      "Accuracy 10000 test images: 96.62 %\n",
      "[6,   300] loss: 0.109 Classification loss:0.090 angle_grad:-0.001 shift_y_grad:0.067 scale_grad:16.361\n",
      "[6,   600] loss: 0.113 Classification loss:0.159 angle_grad:0.000 shift_y_grad:-0.071 scale_grad:9.913\n",
      "[6,   900] loss: 0.111 Classification loss:0.081 angle_grad:-0.002 shift_y_grad:0.000 scale_grad:16.472\n",
      "Accuracy 10000 test images: 96.72 %\n",
      "[7,   300] loss: 0.099 Classification loss:0.066 angle_grad:0.004 shift_y_grad:0.000 scale_grad:17.311\n",
      "[7,   600] loss: 0.104 Classification loss:0.144 angle_grad:0.000 shift_y_grad:0.000 scale_grad:6.577\n",
      "[7,   900] loss: 0.101 Classification loss:0.065 angle_grad:0.000 shift_y_grad:0.000 scale_grad:11.561\n",
      "Accuracy 10000 test images: 96.85 %\n",
      "[8,   300] loss: 0.092 Classification loss:0.068 angle_grad:0.000 shift_y_grad:0.056 scale_grad:9.611\n",
      "[8,   600] loss: 0.096 Classification loss:0.129 angle_grad:0.032 shift_y_grad:0.000 scale_grad:27.736\n",
      "[8,   900] loss: 0.093 Classification loss:0.066 angle_grad:0.020 shift_y_grad:0.000 scale_grad:5.254\n",
      "Accuracy 10000 test images: 96.94 %\n",
      "[9,   300] loss: 0.086 Classification loss:0.071 angle_grad:-0.004 shift_y_grad:0.000 scale_grad:6.764\n",
      "[9,   600] loss: 0.091 Classification loss:0.124 angle_grad:0.013 shift_y_grad:0.000 scale_grad:8.695\n",
      "[9,   900] loss: 0.088 Classification loss:0.056 angle_grad:0.034 shift_y_grad:0.000 scale_grad:38.692\n",
      "Accuracy 10000 test images: 97.13 %\n",
      "[10,   300] loss: 0.080 Classification loss:0.061 angle_grad:-0.006 shift_y_grad:0.100 scale_grad:21.630\n",
      "[10,   600] loss: 0.085 Classification loss:0.132 angle_grad:-0.010 shift_y_grad:0.029 scale_grad:5.723\n",
      "[10,   900] loss: 0.083 Classification loss:0.051 angle_grad:0.000 shift_y_grad:-0.005 scale_grad:9.527\n",
      "Accuracy 10000 test images: 97.15 %\n",
      "[11,   300] loss: 0.076 Classification loss:0.076 angle_grad:0.000 shift_y_grad:0.000 scale_grad:3.561\n",
      "[11,   600] loss: 0.079 Classification loss:0.136 angle_grad:0.059 shift_y_grad:0.032 scale_grad:0.000\n",
      "[11,   900] loss: 0.080 Classification loss:0.055 angle_grad:0.013 shift_y_grad:0.025 scale_grad:5.189\n",
      "Accuracy 10000 test images: 97.35 %\n",
      "[12,   300] loss: 0.071 Classification loss:0.052 angle_grad:0.000 shift_y_grad:0.000 scale_grad:7.295\n",
      "[12,   600] loss: 0.076 Classification loss:0.093 angle_grad:0.031 shift_y_grad:0.020 scale_grad:13.662\n",
      "[12,   900] loss: 0.075 Classification loss:0.048 angle_grad:0.000 shift_y_grad:0.000 scale_grad:15.934\n",
      "Accuracy 10000 test images: 97.33 %\n",
      "[13,   300] loss: 0.067 Classification loss:0.069 angle_grad:-0.003 shift_y_grad:0.088 scale_grad:4.377\n",
      "[13,   600] loss: 0.072 Classification loss:0.111 angle_grad:-0.003 shift_y_grad:0.000 scale_grad:4.230\n",
      "[13,   900] loss: 0.072 Classification loss:0.035 angle_grad:0.041 shift_y_grad:0.021 scale_grad:6.428\n",
      "Accuracy 10000 test images: 97.36 %\n",
      "[14,   300] loss: 0.064 Classification loss:0.031 angle_grad:-0.007 shift_y_grad:0.000 scale_grad:8.261\n",
      "[14,   600] loss: 0.069 Classification loss:0.102 angle_grad:0.000 shift_y_grad:0.012 scale_grad:7.785\n",
      "[14,   900] loss: 0.068 Classification loss:0.037 angle_grad:0.013 shift_y_grad:0.000 scale_grad:1.754\n",
      "Accuracy 10000 test images: 97.61 %\n",
      "[15,   300] loss: 0.061 Classification loss:0.046 angle_grad:0.009 shift_y_grad:0.000 scale_grad:1.796\n",
      "[15,   600] loss: 0.067 Classification loss:0.102 angle_grad:0.000 shift_y_grad:0.009 scale_grad:2.126\n",
      "[15,   900] loss: 0.066 Classification loss:0.038 angle_grad:0.016 shift_y_grad:0.000 scale_grad:17.947\n",
      "Accuracy 10000 test images: 97.49 %\n",
      "Finished Training\n",
      "W noise Accuracy 10000 test images: 97.49 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SAT\"\"\"\n",
    "scale = 1.0\n",
    "angle = 0.0\n",
    "shift_y = 0.0\n",
    "\n",
    "for epoch in range(15):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "        inputs = inputs.view(inputs.size(0), -1).to(Device)  # 将输入数据展平\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        scale_init = scale\n",
    "        angle_init = angle\n",
    "        shift_y_init = shift_y\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #### Perturbation and update non-differentiable parameters\n",
    "        if i % 3 == 0:\n",
    "            perturb_ang = (torch.clamp(torch.rand(1)*1.0,min=0.0,max=2.0)).to(Device)\n",
    "            perturb_ang_np = perturb_ang.cpu().detach().numpy()\n",
    "            angle = float(angle + perturb_ang)\n",
    "        if i % 3 == 1:\n",
    "            perturb_shif = (torch.clamp(torch.rand(1)*1.0,min=0.0,max=2.0)).to(Device)\n",
    "            perturb_shif_np = perturb_shif.cpu().detach().numpy()\n",
    "            shift_y = float(shift_y + perturb_shif)\n",
    "        if i % 3 == 2:\n",
    "            perturb_scal = (torch.clamp(torch.rand(1)*0.05,min=0,max=0.1)).to(Device)\n",
    "            perturb_scal_np = perturb_scal.cpu().detach().numpy()\n",
    "            scale = float(scale + perturb_scal)           \n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss_new = criterion(outputs, labels) \n",
    "        if i % 3 == 0:\n",
    "            angle_grad = (loss_new - loss)/perturb_ang ### 计算梯度\n",
    "        if i % 3 == 1:\n",
    "            shift_y_grad = (loss_new - loss)/perturb_shif ### 计算梯度\n",
    "        if i % 3 == 2:\n",
    "            scale_grad = (loss_new - loss)/perturb_scal ### 计算梯度\n",
    "\n",
    "        if i % 3 == 0:\n",
    "            angle_ascent = angle_grad ### Normalize grad\n",
    "            angle = angle + angle_ascent * 0.8\n",
    "            angle = float(angle.data.detach().cpu().numpy()[0]) \n",
    "        if i % 3 == 1:\n",
    "            shift_y_ascent = shift_y_grad ### Normalize grad\n",
    "            shift_y = shift_y + shift_y_ascent * 0.8\n",
    "            shift_y = float(shift_y.data.detach().cpu().numpy()[0])  \n",
    "        if i % 3 == 2:\n",
    "            scale_ascent = scale_grad ### Normalize grad        \n",
    "            scale = scale + scale_ascent * 0.003\n",
    "            scale = float(scale.data.detach().cpu().numpy()[0])\n",
    "            scale = np.clip(scale,1,1.1)                           \n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "        \n",
    "        outputs_sam = net(inputs)\n",
    "        loss_sam = criterion(outputs_sam, labels)\n",
    "        loss_sam.backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        \n",
    "        scale = scale_init\n",
    "        angle = angle_init\n",
    "        shift_y = shift_y_init\n",
    "              \n",
    "        running_loss += loss.item()\n",
    "        if i % 300 == 299:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 300:.3f} Classification loss:{loss.cpu().detach().numpy():.3f} angle_grad:{angle_grad.cpu().detach().numpy()[0]:.3f} shift_y_grad:{shift_y_grad.cpu().detach().numpy()[0]:.3f} scale_grad:{scale_grad.cpu().detach().numpy()[0]:.3f}')           \n",
    "            running_loss = 0.0\n",
    "    net.apply_constraints()\n",
    "    scheduler.step()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "            inputs = inputs.view(inputs.size(0), -1) \n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(inputs)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy 10000 test images: {100 * correct / total} %')\n",
    "print('Finished Training')\n",
    "y_pred = []\n",
    "t_pred = []\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "    inputs = inputs.view(-1, 784)\n",
    "    # calculate outputs by running images through the network\n",
    "    outputs = net(inputs)\n",
    "    # the class with the highest energy is what we choose as prediction\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    y = predicted.view(-1).cpu().detach().numpy()\n",
    "    t = labels.view(-1).cpu().detach().numpy()\n",
    "    for i in range(len(predicted)):\n",
    "        y_pred.append(y[i])\n",
    "        t_pred.append(t[i])\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print(f'W noise Accuracy 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9555fc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 0.090 Classification loss:0.049 angle_grad:0.209 shift_y_grad:0.060\n",
      "[1,   600] loss: 0.089 Classification loss:0.176 angle_grad:0.053 shift_y_grad:0.457\n",
      "[1,   900] loss: 0.091 Classification loss:0.103 angle_grad:-0.025 shift_y_grad:-0.011\n",
      "Accuracy 10000 test images: 96.99 %\n",
      "[2,   300] loss: 0.092 Classification loss:0.053 angle_grad:-0.004 shift_y_grad:-0.026\n",
      "[2,   600] loss: 0.094 Classification loss:0.178 angle_grad:-0.041 shift_y_grad:-0.011\n",
      "[2,   900] loss: 0.090 Classification loss:0.101 angle_grad:-0.020 shift_y_grad:-0.035\n",
      "Accuracy 10000 test images: 96.96 %\n",
      "[3,   300] loss: 0.089 Classification loss:0.051 angle_grad:0.036 shift_y_grad:0.054\n",
      "[3,   600] loss: 0.092 Classification loss:0.138 angle_grad:0.013 shift_y_grad:0.105\n",
      "[3,   900] loss: 0.091 Classification loss:0.078 angle_grad:-0.035 shift_y_grad:-0.014\n",
      "Accuracy 10000 test images: 96.68 %\n",
      "Finished Training\n",
      "W noise Accuracy 10000 test images: 96.68 %\n"
     ]
    }
   ],
   "source": [
    "# \"\"\"SAT\"\"\"\n",
    "# scale = 1.0\n",
    "# angle = 0.0\n",
    "# shift_y = 0.0\n",
    "\n",
    "# for epoch in range(3):  # loop over the dataset multiple times\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(trainloader, 0):\n",
    "#         # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "#         inputs = inputs.view(inputs.size(0), -1).to(Device)  # 将输入数据展平\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         scale_init = scale\n",
    "#         angle_init = angle\n",
    "#         shift_y_init = shift_y\n",
    "        \n",
    "#         outputs = net(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "        \n",
    "#         #### Perturbation and update non-differentiable parameters\n",
    "#         # if i % 2 == 0:\n",
    "#         perturb_ang = (torch.clamp(torch.rand(1)*3.0,min=0.0,max=3.0)).to(Device)\n",
    "#         perturb_ang_np = perturb_ang.cpu().detach().numpy()\n",
    "#         angle = float(angle + perturb_ang)\n",
    "#         # if i % 2 == 1:\n",
    "#         perturb_shif = (torch.clamp(torch.rand(1)*3.0,min=0.0,max=3.0)).to(Device)\n",
    "#         perturb_shif_np = perturb_shif.cpu().detach().numpy()\n",
    "#         shift_y = float(shift_y + perturb_shif)      \n",
    "\n",
    "#         outputs = net(inputs)\n",
    "\n",
    "#         loss_new = criterion(outputs, labels) \n",
    "#         # if i % 2 == 0:\n",
    "#         angle_grad = (loss_new - loss)/perturb_ang ### 计算梯度\n",
    "#         # if i % 2 == 1:\n",
    "#         shift_y_grad = (loss_new - loss)/perturb_shif ### 计算梯度\n",
    "\n",
    "#         # if i % 2 == 0:\n",
    "#         angle_ascent = angle_grad ### Normalize grad\n",
    "#         angle = angle + angle_ascent * 0.8\n",
    "#         angle = float(angle.data.detach().cpu().numpy()[0]) \n",
    "#         # if i % 2 == 1:\n",
    "#         shift_y_ascent = shift_y_grad ### Normalize grad\n",
    "#         shift_y = shift_y + shift_y_ascent * 0.8\n",
    "#         shift_y = float(shift_y.data.detach().cpu().numpy()[0])                      \n",
    "        \n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.first_step(zero_grad=True)\n",
    "        \n",
    "#         outputs_sam = net(inputs)\n",
    "#         loss_sam = criterion(outputs_sam, labels)\n",
    "#         loss_sam.backward()\n",
    "#         optimizer.second_step(zero_grad=True)\n",
    "        \n",
    "#         scale = scale_init\n",
    "#         angle = angle_init\n",
    "#         shift_y = shift_y_init\n",
    "              \n",
    "#         running_loss += loss.item()\n",
    "#         if i % 300 == 299:    # print every 2000 mini-batches\n",
    "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 300:.3f} Classification loss:{loss.cpu().detach().numpy():.3f} angle_grad:{angle_grad.cpu().detach().numpy()[0]:.3f} shift_y_grad:{shift_y_grad.cpu().detach().numpy()[0]:.3f}')           \n",
    "#             running_loss = 0.0\n",
    "#     net.apply_constraints()\n",
    "#     scheduler.step()\n",
    "#     total = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data in testloader:\n",
    "#             inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "#             inputs = inputs.view(inputs.size(0), -1) \n",
    "#             # calculate outputs by running images through the network\n",
    "#             outputs = net(inputs)\n",
    "#             # the class with the highest energy is what we choose as prediction\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#     print(f'Accuracy 10000 test images: {100 * correct / total} %')\n",
    "# print('Finished Training')\n",
    "# y_pred = []\n",
    "# t_pred = []\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# for data in testloader:\n",
    "#     inputs, labels = data[0].to(Device), data[1].to(Device)\n",
    "#     inputs = inputs.view(-1, 784)\n",
    "#     # calculate outputs by running images through the network\n",
    "#     outputs = net(inputs)\n",
    "#     # the class with the highest energy is what we choose as prediction\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     y = predicted.view(-1).cpu().detach().numpy()\n",
    "#     t = labels.view(-1).cpu().detach().numpy()\n",
    "#     for i in range(len(predicted)):\n",
    "#         y_pred.append(y[i])\n",
    "#         t_pred.append(t[i])\n",
    "#     total += labels.size(0)\n",
    "#     correct += (predicted == labels).sum().item()\n",
    "# print(f'W noise Accuracy 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1625f872c3297ecf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:13:28.099545Z",
     "start_time": "2025-05-30T05:13:28.089304Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net_sam=net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48519eac6a567546",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:13:30.820945Z",
     "start_time": "2025-05-30T05:13:30.813188Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Define NN class\"\"\"\n",
    "class InCoFCNet_test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InCoFCNet_test, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 144)\n",
    "        self.fc2 = nn.Linear(144, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = f_wn_1(x,self.fc1.weight.t())+self.fc1.bias\n",
    "        x = F.sigmoid(x)\n",
    "        x = f_wn_2(x,self.fc2.weight.t())+self.fc2.bias\n",
    "        return x\n",
    "    \n",
    "    def apply_constraints(self):\n",
    "        self.fc1.weight.data = torch.clamp(self.fc1.weight.data,-1,1)        \n",
    "        self.fc2.weight.data = torch.clamp(self.fc2.weight.data,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cede2b319e10491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T05:13:31.759313Z",
     "start_time": "2025-05-30T05:13:31.749617Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# net_test=InCoFCNet_test()\n",
    "# net_test.fc1=net_ref.fc1\n",
    "# net_test.fc2=net_ref.fc2\n",
    "net_test_sam=InCoFCNet_test()\n",
    "net_test_sam.fc1=net_sam.fc1\n",
    "net_test_sam.fc2=net_sam.fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5e0c3048014488f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T03:15:14.568106Z",
     "start_time": "2025-05-30T03:15:14.558839Z"
    }
   },
   "outputs": [],
   "source": [
    "# PATH = 'Training Results/standard_bp.pth'\n",
    "# torch.save(net_test.state_dict(), PATH)\n",
    "# PATH = ''\n",
    "# PATH = 'Training Results/sat-angle shift scale.pth'\n",
    "# torch.save(net_test_sam.state_dict(), PATH)\n",
    "# PATH = ''\n",
    "# PATH = 'Training Results/sat-angle shift.pth'\n",
    "# torch.save(net_test_sam.state_dict(), PATH)\n",
    "# PATH = ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
