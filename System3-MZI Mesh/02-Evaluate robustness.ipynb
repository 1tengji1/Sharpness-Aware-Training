{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-05T11:55:17.723813Z",
     "start_time": "2025-06-05T11:55:15.093881Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\GPU_Pytorchpy39\\lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "72f20262f76576c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T11:55:18.449494Z",
     "start_time": "2025-06-05T11:55:18.397772Z"
    }
   },
   "source": [
    "transform = transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "                                   torchvision.transforms.Normalize(\n",
    "                                       (0.1307,), (0.3081,))])\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "866e5ba0d7f1ca53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T11:55:24.070992Z",
     "start_time": "2025-06-05T11:55:20.937940Z"
    }
   },
   "source": [
    "from mnist import *\n",
    "from viz import *\n",
    "\n",
    "import torch\n",
    "from torch.nn import Sequential, Module, CrossEntropyLoss\n",
    "from torch.nn.functional import normalize\n",
    "import numpy as np\n",
    "from neurophoxTorch.torch import RMTorch\n",
    "from scipy.stats import unitary_group\n",
    "from tqdm import tqdm_notebook as pbar\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "def rc_mul(real: torch.Tensor, comp: torch.Tensor):\n",
    "    return real.unsqueeze(dim=0) * comp\n",
    "\n",
    "\n",
    "def cc_mul(comp1: torch.Tensor, comp2: torch.Tensor) -> torch.Tensor:\n",
    "    real = comp1[0] * comp2[0] - comp1[1] * comp2[1]\n",
    "    comp = comp1[0] * comp2[1] + comp1[1] * comp2[0]\n",
    "    return torch.stack((real, comp), dim=0)\n",
    "\n",
    "def phasor(real: torch.Tensor):\n",
    "    return torch.stack((real.cos(), real.sin()), dim=0)\n",
    "\n",
    "\n",
    "def cnorm(comp: torch.Tensor):\n",
    "    return (comp[0] ** 2 + comp[1] ** 2).sqrt()\n",
    "\n",
    "\n",
    "def cnormsq(comp: torch.Tensor):\n",
    "    return comp[0] ** 2 + comp[1] ** 2\n",
    "\n",
    "\n",
    "def to_complex_t(nparray: np.ndarray):\n",
    "    return torch.stack((torch.as_tensor(nparray.real),\n",
    "                        torch.as_tensor(nparray.imag)), dim=0)\n",
    "\n",
    "\n",
    "class ElectroopticNonlinearity(Module):\n",
    "    def __init__(self, alpha: float=0.1, g: float=0.05 * np.pi, phi_b: float=np.pi):\n",
    "        super(ElectroopticNonlinearity, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.g = g\n",
    "        self.phi_b = phi_b\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        phase = 0.5 * self.g * cnormsq(inputs) + 0.5 * self.phi_b\n",
    "        return np.sqrt(1 - self.alpha) * cc_mul(rc_mul(phase.cos(), phasor(-phase)), inputs)\n",
    "\n",
    "\n",
    "class CNormSq(Module):\n",
    "    def __init__(self, normed=True):\n",
    "        super(CNormSq, self).__init__()\n",
    "        self.normed = normed\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return normalize(cnormsq(inputs), dim=1) if self.normed else cnormsq(inputs)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ResearchProject\\PNNRobustOptimization\\OpenSourceCodes\\System3-MZI Mesh\\mnist.py:2: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.5)\n",
      "  import scipy as sp\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "2cd982907a3c3661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T11:55:27.186979Z",
     "start_time": "2025-06-05T11:55:25.865380Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 64)\n",
    "        self.norm1 = nn.BatchNorm2d(6)\n",
    "        self.norm2 = nn.BatchNorm2d(16)\n",
    "        self.norm3 = nn.BatchNorm1d(120)\n",
    "        self.layer1 = RMTorch(64,phase_error = 0.0, phase_error_files = None,bs_error=0.0,bs_error_files = None)\n",
    "        self.output = CNormSq()\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = F.max_pool2d(F.relu(self.norm1(self.conv1(x))), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.norm2(self.conv2(x))), (2, 2))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.fc2(x)\n",
    "        self.feature3 = x.detach()\n",
    "        x = torch.stack((x, torch.zeros(x.shape, dtype=torch.float32, device=x.device)), dim=0)\n",
    "        x,_,_,_ = self.layer1(x)\n",
    "        self.feature4 = x.detach()\n",
    "        x = self.output(x)\n",
    "        self.feature5 = x.detach()\n",
    "\n",
    "        return x\n",
    "\n",
    "    def apply_constraints(self):\n",
    "        self.conv1.cuda().weight.data = torch.clamp(self.conv1.cuda().weight.data, -1, 1)\n",
    "        self.conv2.cuda().weight.data = torch.clamp(self.conv2.cuda().weight.data, -1, 1)\n",
    "        self.fc1.cuda().weight.data = torch.clamp(self.fc1.cuda().weight.data, -1, 1)\n",
    "        self.fc2.cuda().weight.data = torch.clamp(self.fc2.cuda().weight.data, -1, 1)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "net = LeNet5()\n",
    "net.to(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=64, bias=True)\n",
       "  (norm1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm3): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): RMTorch()\n",
       "  (output): CNormSq()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "522bb584d509dde6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T11:57:06.295958Z",
     "start_time": "2025-06-05T11:57:06.256792Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyhessian import hessian # Hessian computation\n",
    "# This is a simple function, that will allow us to perturb the model parameters and get the result\n",
    "def get_params(model_orig, direction, alpha):\n",
    "    model_perb = LeNet5()  # Create a new model\n",
    "    state_dict = torch.load(PATH)\n",
    "    state_dict = {k: v for k, v in state_dict.items() if 'cn1' not in k}\n",
    "    state_dict = {k: v for k, v in state_dict.items() if 'cn2' not in k}\n",
    "    state_dict = {k: v for k, v in state_dict.items() if 'cn3' not in k}\n",
    "    state_dict = {k: v for k, v in state_dict.items() if 'cn4' not in k}    \n",
    "    state_dict = {k: v for k, v in state_dict.items() if 'cn5' not in k}\n",
    "    state_dict = {k: v for k, v in state_dict.items() if 'cn6' not in k}   \n",
    "    model_perb.load_state_dict(state_dict)  # Copy original model parameters\n",
    "    model_perb = model_perb.cuda()  # Move new model to CUDA\n",
    "    for m_orig, m_perb, d in zip(model_orig.parameters(), model_perb.parameters(), direction):\n",
    "        m_perb.data = m_orig.data + alpha * d\n",
    "    return model_perb\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load models\n",
    "# PATH = './Training Results/01-Standard BP.pth'\n",
    "# PATH = './Training Results/02-PAT.pth'\n",
    "# PATH = './Training Results/03-SAT-In silico.pth'\n",
    "# PATH = './Training Results/04-SAT-In situ.pth'\n",
    "# PATH = './Training Results/05-DAT.pth'\n",
    "PATH = './Training Results/06-NAT.pth'\n",
    "\n",
    "net = LeNet5()\n",
    "state_dict = torch.load(PATH)\n",
    "state_dict = {k: v for k, v in state_dict.items() if 'cn1' not in k}\n",
    "state_dict = {k: v for k, v in state_dict.items() if 'cn2' not in k}\n",
    "state_dict = {k: v for k, v in state_dict.items() if 'cn3' not in k}\n",
    "state_dict = {k: v for k, v in state_dict.items() if 'cn4' not in k}    \n",
    "state_dict = {k: v for k, v in state_dict.items() if 'cn5' not in k}\n",
    "state_dict = {k: v for k, v in state_dict.items() if 'cn6' not in k}\n",
    "net.load_state_dict(state_dict)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "7ad2d56d42e411e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T11:57:16.342825Z",
     "start_time": "2025-06-05T11:57:06.584112Z"
    }
   },
   "source": [
    "# Define perturbation range\n",
    "lams_wo = np.linspace(-0.3, 0.3, 201).astype(np.float32)\n",
    "loss_list_wo = []\n",
    "\n",
    "# Set model to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Select a fixed batch of data\n",
    "n = 0\n",
    "dataiter = iter(testloader)\n",
    "for _ in range(n - 1):\n",
    "    next(dataiter)  # Skip the first n-1 batches\n",
    "n_batch = next(dataiter)  # Get the n-th batch\n",
    "inputs, targets = n_batch[0].to(device), n_batch[1].to(device)\n",
    "\n",
    "# Ensure data is on the correct device\n",
    "inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "# Create the Hessian computation module\n",
    "net.to(device)\n",
    "hessian_comp = hessian(net, criterion, data=(inputs, targets), cuda=True)\n",
    "\n",
    "# Compute the top eigenvalue and eigenvector\n",
    "top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues()\n",
    "print(\"The top Hessian eigenvalue of this model is %.4f\" % top_eigenvalues[-1])\n",
    "trace = hessian_comp.trace()\n",
    "print(\"The trace of this model is: %.4f\" % (np.mean(trace)))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top Hessian eigenvalue of this model is 96.7924\n",
      "The trace of this model is: 1045.5142\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbdecb536173bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
